{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load libraries and initialize constants..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt, matplotlib.colors as colors, matplotlib.path as mpath\n",
    "from matplotlib.patches import FancyArrowPatch, Circle, Wedge, Polygon, PathPatch\n",
    "from numpy.polynomial.polynomial import polyfit\n",
    "from scipy.optimize import curve_fit, fmin_cobyla\n",
    "\n",
    "import math, numbers, string, re, itertools, random, copy\n",
    "import numpy as np, pandas as pd\n",
    "import scipy.stats as stats\n",
    "import collections as collect\n",
    "import seaborn as sns\n",
    "import networkx as nx\n",
    "import colorcet as cc\n",
    "import functools as func\n",
    "import operator as operate\n",
    "from pprint import pprint\n",
    "\n",
    "%matplotlib inline\n",
    "sns.set_style(\"dark\")\n",
    "\n",
    "GRAPH_WIDTH = 20\n",
    "GRAPH_HEIGHT = 20\n",
    "GRAPH_DOTS_PER_INCH = 160\n",
    "MAX_STEP_COUNT = 5\n",
    "EDGE_CURVE_OFFSET_RATIO = 0.1\n",
    "\n",
    "SPLIT_CIRCLE_ANGLE_0 = 30\n",
    "SPLIT_CIRCLE_ANGLE_1 = 150\n",
    "SPLIT_CIRCLE_ANGLE_2 = 270\n",
    "\n",
    "CGRAPH_RADIUS_MULTIPLIER = 1.2\n",
    "CGRAPH_LABEL_RADIUS_MULTIPLIER = 1.25\n",
    "CGRAPH_LEGEND_RADIUS_MULTIPLIER = 1.35\n",
    "\n",
    "GRAPH_TITLE = 'Entropy Map:'\n",
    "GRAPH_DATASET_LABEL = 'Entropy rate for\\ntotal dataset:\\n%.2f bits'\n",
    "GRAPH_TITLE_2 = \"Mutual Information Map\\nfor '%s':\"\n",
    "GRAPH_DATASET_LABEL_2 = \"Entropy rate for\\n%s field:\\n%.2f bits\"\n",
    "RADIUS_FOR_TOTAL_ENTROPY = 0.07\n",
    "RADIUS_FOR_TOTAL_MUTUAL_INFORMATION = 0.07\n",
    "\n",
    "BACKGROUND_COLOR = '#000000' #'#002000'#'#222222' #'#111111' \n",
    "FONT_COLOR = 'white'\n",
    "ENTROPY_BACKGROUND_COLOR = 'lightgray'\n",
    "\n",
    "ENTROPY_CMAP = cc.cm['bkr'] # 'RdYlBu' # 'coolwarm' # 'YlOrRd' # YlOrRd' #'Set3' # 'binary\n",
    "ENTROPY_CMAP2 = cc.cm['bky'] # 'diverging_linear_bjy_30_90_c45' # 'bgy'  # 'bjy' # 'RdYlGn'\n",
    "TAB_CMAP = plt.get_cmap('tab20')\n",
    "\n",
    "LETTER_COLOR_DICT = { c: TAB_CMAP(i/20.0) for (i, c) in enumerate(string.ascii_uppercase[:20]) }\n",
    "HIGHLIGHT_DICT = {\n",
    "        'out2n':'#550000', 'out1n':'#550000', 'out1p':'#550000', 'out2p':'#550000'\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Load in data from file..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#aDF = pd.read_csv(\"Edmonton_Arts_Council_10_Year_Strategic_Plan_-_Edmonton_Insight_Community.csv\")\n",
    "#cL = list(aDF.columns)\n",
    "#for i, c in enumerate(cL):\n",
    "#    c = re.sub('^Q\\d+\\w?(_ArtsCouncil)?_', '', c)\n",
    "#    c = re.sub('\\s*\\(Source\\:\\s.*\\)$', '', c)\n",
    "#    cL[i] = c\n",
    "#aDF.columns = pd.Index(cL)\n",
    "#aDF = aDF[list(aDF.columns[2:10])]\n",
    "\n",
    "#aDF = pd.read_csv('nyc_subway_weather.csv')\n",
    "aDF = pd.read_csv('winequality-red.csv', sep=';')\n",
    "#aDF = aDF[aDF.columns[:14]]\n",
    "#aDF = aDF[['UNIT', 'DATEn', 'TIMEn', 'ENTRIESn_hourly', 'EXITSn_hourly', 'weekday', \n",
    "#          'conds', 'fog', 'precipi', 'pressurei', 'tempi', 'wspdi']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "aDF.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "aDF.describe(include='all')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Alternatively, produce a synthetic data set for testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "TEST_CATEGORIES = ['cA', 'cB', 'cC', 'cD', 'cE', 'cF', 'cG', 'cH']\n",
    "\n",
    "def get_random_cat_p_ranges():\n",
    "    nL = [0.2 + random.random() * 0.8 for i in range(8)]\n",
    "    pL, d = [0], sum(nL)\n",
    "    for n in nL: pL.append(pL[-1]+n/d) \n",
    "    return pL\n",
    "\n",
    "def get_cat_by_defcat_ranges(category_ranges):\n",
    "    c, v = None, random.random() \n",
    "    for i in range(8):\n",
    "        if category_ranges[i] <= v < category_ranges[i+1]:\n",
    "            c = TEST_CATEGORIES[i]\n",
    "            break\n",
    "    return c\n",
    "\n",
    "def get_modelDict(r0_count=2, rp1_count=2, rp2_count=1, rn2_count=1):\n",
    "    fi, fDcprL, rDpL = 1, {}, {}\n",
    "    for c0 in range(r0_count):\n",
    "        fDcprL['f%d' % (fi)] = get_random_cat_p_ranges()\n",
    "        fi += 1\n",
    "    for c1 in range(rp1_count):\n",
    "        fDcprL['f%da' % (fi)] = get_random_cat_p_ranges()\n",
    "        fDcprL['f%db' % (fi)] = get_random_cat_p_ranges()\n",
    "        rDpL[('f%da' % (fi), 'f%db' % (fi))] = [random.random() for i in range(8)] \n",
    "        fi += 1\n",
    "    for c2 in range(rp2_count):\n",
    "        fDcprL['f%da' % (fi)] = get_random_cat_p_ranges()\n",
    "        fDcprL['f%db' % (fi)] = get_random_cat_p_ranges()\n",
    "        fDcprL['f%dc' % (fi)] = get_random_cat_p_ranges()\n",
    "        rDpL[('f%da' % (fi), 'f%db' % (fi))] = [random.random() for i in range(8)] \n",
    "        rDpL[('f%db' % (fi), 'f%dc' % (fi))] = [random.random() for i in range(8)] \n",
    "        fi += 1\n",
    "    for c3 in range(rn2_count):\n",
    "        fDcprL['f%da' % (fi)] = get_random_cat_p_ranges()\n",
    "        fDcprL['f%db' % (fi)] = get_random_cat_p_ranges()\n",
    "        fDcprL['f%dc' % (fi)] = get_random_cat_p_ranges()\n",
    "        rDpL[('f%da' % (fi), 'f%db' % (fi), 'f%dc' % (fi))] = [random.random() for i in range(8)]\n",
    "        fi += 1\n",
    "\n",
    "    return {'fields': fDcprL, 'relations': rDpL}\n",
    "            \n",
    "def get_sampleDFrame(modelD, sample_count):\n",
    "    fDcprL, rDpL, fn1, fn2, fDvL = modelD['fields'], modelD['relations'], None, None, {}\n",
    "    for f in sorted(fDcprL):\n",
    "        rn2, rn1, fDvL[f] = (fn2, fn1, f), (fn1, f), []\n",
    "        for i in range(sample_count):\n",
    "            v, rv = None, random.random()\n",
    "            if rn2 in rDpL:\n",
    "                vn2, vn1 = fDvL[fn2][i], fDvL[fn1][i]    \n",
    "                v0 = TEST_CATEGORIES[(TEST_CATEGORIES.index(vn1)+TEST_CATEGORIES.index(vn2)+1) % 8]\n",
    "                tv = rDpL[rn2][TEST_CATEGORIES.index(vn2)]\n",
    "                v = v0 if rv < tv else get_cat_by_defcat_ranges(fDcprL[f])\n",
    "            elif rn1 in rDpL:\n",
    "                vn1 = fDvL[fn1][i]\n",
    "                v0 = TEST_CATEGORIES[(TEST_CATEGORIES.index(vn1)+1) % 8]\n",
    "                tv = rDpL[rn1][TEST_CATEGORIES.index(vn1)]\n",
    "                v = v0 if rv < tv else get_cat_by_defcat_ranges(fDcprL[f])\n",
    "            else: \n",
    "                v = get_cat_by_defcat_ranges(fDcprL[f])\n",
    "            fDvL[f].append(v)\n",
    "        fn2 = fn1\n",
    "        fn1 = f  \n",
    "    return pd.DataFrame(fDvL)\n",
    "    \n",
    "mD = get_modelDict(0, 0, 2, 2)\n",
    "\n",
    "mD2 = copy.deepcopy(mD)\n",
    "\n",
    "#mD2['fields']['f1a'] = get_random_cat_p_ranges()\n",
    "#mD2['fields']['f1b'] = get_random_cat_p_ranges()\n",
    "#mD2['fields']['f1c'] = get_random_cat_p_ranges()\n",
    "#mD2['fields']['f2a'] = get_random_cat_p_ranges()\n",
    "#mD2['fields']['f2b'] = get_random_cat_p_ranges()\n",
    "#mD2['fields']['f2c'] = get_random_cat_p_ranges()\n",
    "#mD2['fields']['f3a'] = get_random_cat_p_ranges()\n",
    "#mD2['fields']['f3b'] = get_random_cat_p_ranges()\n",
    "#mD2['fields']['f3c'] = get_random_cat_p_ranges()\n",
    "#mD2['fields']['f4a'] = get_random_cat_p_ranges()\n",
    "#mD2['fields']['f4b'] = get_random_cat_p_ranges()\n",
    "#mD2['fields']['f4c'] = get_random_cat_p_ranges()\n",
    "#mD2['relations'][('f2a', 'f2b')] = [random.random() for i in range(8)]\n",
    "mD2['relations'][('f2b', 'f2c')] = [random.random() for i in range(8)]\n",
    "mD2['relations'][('f4a', 'f4b', 'f4c')] = [random.random() for i in range(8)]\n",
    "\n",
    "eDF = get_sampleDFrame(mD, 10000)\n",
    "eDFc = get_sampleDFrame(mD2, 10000)\n",
    "eDF.describe(include='all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "eDFc.describe(include='all')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Discretize data..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def discretize_data_SS(SS):\n",
    "    SS2, dSS, u = SS, SS.describe(include='all'), None\n",
    "    if 'unique' in dSS.index:\n",
    "        SS = SS.fillna('Not Recorded')\n",
    "        vDnv = {k: 'v'+str(i+1) for i, k in enumerate(sorted(collect.Counter(SS).keys()))}\n",
    "        SS2 = SS.apply(lambda v: vDnv[v])\n",
    "    else:\n",
    "        is_not_assigned = True\n",
    "        q125, q375, q625, q875 = SS.quantile(0.125), SS.quantile(0.375), SS.quantile(0.625), SS.quantile(0.875)\n",
    "        q250, q500, q750 = dSS['25%'], dSS['50%'], dSS['75%']\n",
    "        if (q125 != q250 != q375 != q500 != q625 != q750 != q875):\n",
    "            SS2 = SS.apply(lambda v: 'e1' if v<q125 else ('e2' if v<q250 else ('e3' if v<q375 else ('e4' if v<q500 \\\n",
    "                           else ('e5' if v<q625 else ('e6' if v<q750 else ('e7' if v<q875 else 'e8')))))))\n",
    "            is_not_assigned = False\n",
    "        if is_not_assigned and (q250 != q500 != q750):\n",
    "            SS2 = SS.apply(lambda v: 'q1' if v<q250 else ('q2' if v<q500 else ('q3' if v<q750 else 'q4')))\n",
    "            is_not_assigned = False\n",
    "        q330, q660 = SS.quantile(0.33), SS.quantile(0.66)\n",
    "        if is_not_assigned and (q330 != q660):\n",
    "            SS2 = SS.apply(lambda v: 't1' if v < q330 else ('t2' if v < q660 else 't3'))\n",
    "            is_not_assigned = False\n",
    "        q000, q1000 = SS.min(), SS.max()    \n",
    "        if is_not_assigned and q000 != q500 != q1000:\n",
    "            SS2 = SS.apply(lambda v: 'h1' if v < q500 else 'h2')\n",
    "            is_not_assigned = False\n",
    "        if is_not_assigned:\n",
    "            cval = sorted(collect.Counter(SS).items(), key=lambda kv: kv[1])[-1][0]\n",
    "            SS2 = SS.apply(lambda v: 'mc' if v == cval else 'lc')\n",
    "            is_not_assigned = False\n",
    "        if is_not_assigned:\n",
    "            SS2 = SS.apply(lambda v: 'sv')\n",
    "    return SS2\n",
    "\n",
    "eDF = aDF.apply(discretize_data_SS)\n",
    "eDF.describe(include='all')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Subset dataframe for purposes of comparing distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def subset_DF_on_field_and_value(DF, field, values):\n",
    "    ssaDF = DF.loc[DF[field].isin(values)].drop(field, axis=1)\n",
    "    ssbDF = DF.loc[~DF[field].isin(values)].drop(field, axis=1)\n",
    "    mDF = DF.drop(field, axis=1)\n",
    "    return ssaDF, ssbDF, mDF\n",
    "\n",
    "#eDF, eDFc, _ = subset_DF_on_field_and_value(eDF, 'precipi', ['lc'])\n",
    "#eDF, eDFc, _ = subset_DF_on_field_and_value(eDF, 'weekday', ['lc'])\n",
    "eDF, eDFc, _ = subset_DF_on_field_and_value(eDF, 'quality', ['t3'])\n",
    "#eDF, eDFc, _ = subset_DF_on_field_and_value(eDF, 'pH', ['e7','e8'])\n",
    "#eDF, eDFc, _ = subset_DF_on_field_and_value(eDF, 'density', ['e1','e2'])\n",
    "#eDF, eDFc, _ = subset_DF_on_field_and_value(eDF, 'sulphates', #'total sulfur dioxide', \n",
    "#        ['e1','e2','e3','e4'])\n",
    "\n",
    "eDF.describe(include='all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eDFc.describe(include='all')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Entropy calculation utility functions..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_unique_values_for_SS(SS):\n",
    "    return pd.Series(sorted([v for v in set(SS)]))\n",
    "\n",
    "def get_unique_values_for_DF(DF):\n",
    "    return pd.Series([get_unique_values_for_SS(DF[c]) for c in DF.columns], index=DF.columns)\n",
    "\n",
    "def superkey_DF(DF):\n",
    "    if type(DF) != pd.DataFrame: raise TypeError('Superkey argument must be a DataFrame')\n",
    "    return pd.Series(list(zip(*[DF[c] for c in DF.keys()])), name=tuple(DF.keys()))\n",
    "\n",
    "def get_E_for_SS(SS, cSS=None, tflag=None):\n",
    "    pC = collect.Counter(SS)\n",
    "    e = None    \n",
    "    if cSS is None:\n",
    "        if len(pC) <= 1: raise AssertionError('Series must have at least 2 states')\n",
    "        e = stats.entropy([v + 0.0000001 for v in pC.values()], base=2)\n",
    "    elif cSS is not None:\n",
    "        qC = collect.Counter(cSS)\n",
    "        kL = list(set(pC.keys()) | set(qC.keys()))\n",
    "        if len(kL) <= 1: raise AssertionError('Series must have at least 2 states')\n",
    "        pk, qk = [], []\n",
    "        for k in kL:                \n",
    "            pk.append(((pC[k] if k in pC else 0) + 0.0000001))\n",
    "            qk.append(((qC[k] if k in qC else 0) + 0.0000001))\n",
    "        e = stats.entropy(pk, base=2) + stats.entropy(pk, qk=qk, base=2)\n",
    "    return e\n",
    "\n",
    "def get_max_E_for_SS(SS, cSS=None, tflag=None):\n",
    "    pC = collect.Counter(SS)\n",
    "    e, ps, pl = None, len(SS), len(pC)    \n",
    "    if cSS is None:\n",
    "        if len(pC) <= 1: raise AssertionError('Series must have at least 2 states')\n",
    "        e = stats.entropy([ps/pl + 0.0000001]*pl, base=2)\n",
    "    elif cSS is not None:\n",
    "        qC = collect.Counter(cSS)\n",
    "        kL, qs, ql = list(set(pC.keys()) | set(qC.keys())), len(cSS), len(qC)\n",
    "        if len(kL) <= 1: raise AssertionError('Series must have at least 2 states')\n",
    "        pk, qk = [], []\n",
    "        for k in kL:                \n",
    "            pk.append(((ps/pl if k in pC else 0) + 0.0000001))\n",
    "            qk.append(((qs/ql if k in qC else 0) + 0.0000001))\n",
    "        e = stats.entropy(pk, base=2) + stats.entropy(pk, qk=qk, base=2)\n",
    "    return e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(get_E_for_SS(eDF['citric acid']))\n",
    "#print(get_max_E_for_SS(eDF['citric acid']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_jE_for_DF(DF, cDF=None, tflag=None):\n",
    "    SS, cSS = superkey_DF(DF), superkey_DF(cDF) if cDF is not None else None \n",
    "    return get_E_for_SS(SS, cSS=cSS, tflag=tflag)\n",
    "\n",
    "def get_Es_for_DF(DF, cDF=None, tflag=None):\n",
    "    cL, eL = DF.columns, None\n",
    "    if cDF is None: eL = [get_E_for_SS(DF[c], tflag=tflag) for c in cL]\n",
    "    else: eL = [get_E_for_SS(DF[c], cSS=cDF[c], tflag=tflag) for c in cL]\n",
    "    return pd.Series(eL, index=cL)\n",
    "\n",
    "def get_max_Es_for_DF(DF, cDF=None, tflag=None):\n",
    "    cL, eL = DF.columns, None\n",
    "    if cDF is None: eL = [get_max_E_for_SS(DF[c], tflag=tflag) for c in cL]\n",
    "    else: eL = [get_max_E_for_SS(DF[c], cSS=cDF[c], tflag=tflag) for c in cL]\n",
    "    return pd.Series(eL, index=cL)\n",
    "\n",
    "def get_2v_jEs_for_DF(DF, cDF=None, tflag=None):\n",
    "    cDje = {}\n",
    "    for i, c in enumerate(DF.columns):\n",
    "        cDje[c] = []\n",
    "        for j, c2 in enumerate(DF.columns):\n",
    "            if cDF is None:\n",
    "                cDje[c].append(get_jE_for_DF(DF[[c, c2]], tflag=tflag) if i > j else np.NaN)\n",
    "            else:\n",
    "                cDje[c].append(get_jE_for_DF(DF[[c, c2]], cDF=cDF[[c, c2]], tflag=tflag) \n",
    "                               if i > j else np.NaN)\n",
    "    return pd.DataFrame(cDje, columns=DF.columns, index=DF.columns)\n",
    "\n",
    "def get_2v_MIs_for_DF(DF, cDF=None, tflag=None):\n",
    "    eSS = get_Es_for_DF(DF, cDF=cDF, tflag=tflag)\n",
    "    jeDF = get_2v_jEs_for_DF(DF, cDF=cDF, tflag=tflag)    \n",
    "    return pd.DataFrame({c: [eSS[c]+eSS[c2]-jeDF[c][c2] for c2 in DF.columns] for c in DF.columns}, \n",
    "                        index = DF.columns)\n",
    "\n",
    "def get_max_2v_MIs_for_DF(DF, cDF=None, tflag=None):\n",
    "    eSS = get_max_Es_for_DF(DF, cDF=cDF, tflag=tflag)\n",
    "    return pd.DataFrame({DF.columns[i]: [min(eSS.iloc[j], eSS.iloc[i]) if i > j else np.NaN\n",
    "                             for j in range(DF.shape[1])] for i in range(DF.shape[1])}, \n",
    "                        index = DF.columns)\n",
    "\n",
    "def get_3v_jEs_for_DF(DF, cDF=None, tflag=None):\n",
    "    c1c2c3L, je3L = [], []\n",
    "    for i in range(DF.shape[1]):\n",
    "        for j in range(i+1, DF.shape[1]):\n",
    "            for k in range(j+1, DF.shape[1]):\n",
    "                c1, c2, c3, je3 = DF.columns[i], DF.columns[j], DF.columns[k], None\n",
    "                if cDF is None:\n",
    "                    je3 = get_jE_for_DF( DF[[c1,c2,c3]], tflag=tflag )\n",
    "                else:\n",
    "                    je3 = get_jE_for_DF(DF[[c1,c2,c3]], cDF=cDF[[c1,c2,c3]], tflag=tflag)\n",
    "                c1c2c3L.append((c1,c2,c3))\n",
    "                je3L.append(je3)\n",
    "    return pd.Series(je3L, index=c1c2c3L)\n",
    "\n",
    "def get_3v_MIs_for_DF(DF, cDF=None, tflag=None):\n",
    "    eSS = get_Es_for_DF(DF, cDF=cDF, tflag=tflag)\n",
    "    jeDF = get_2v_jEs_for_DF(DF, cDF=cDF, tflag=tflag)\n",
    "    tjeSS = get_3v_jEs_for_DF(DF, cDF=cDF, tflag=tflag)    \n",
    "    tmiL, cxcyczL = [], []\n",
    "    for i in range(DF.shape[1]):\n",
    "        for j in range(i+1, DF.shape[1]):\n",
    "            for k in range(j+1, DF.shape[1]):\n",
    "                cX, cY ,cZ = DF.columns[i], DF.columns[j], DF.columns[k]\n",
    "                eX, eY, eZ = eSS[cX], eSS[cY], eSS[cZ]\n",
    "                jeXY, jeXZ, jeYZ = jeDF[cY][cX], jeDF[cZ][cX], jeDF[cZ][cY]  \n",
    "                tje = tjeSS[(cX,cY,cZ)]\n",
    "                tmi = tje+eX+eY+eZ-jeXZ-jeXY-jeYZ\n",
    "                tmiL.append(tmi)\n",
    "                cxcyczL.append((cX,cY,cZ))\n",
    "    return pd.Series(tmiL, index=cxcyczL)\n",
    "\n",
    "def get_max_3v_MIs_for_DF(DF, cDF=None, tflag=None):\n",
    "    eSS, tmiL, cxcyczL = get_max_Es_for_DF(DF, cDF=cDF, tflag=tflag), [], []\n",
    "    for i in range(DF.shape[1]):\n",
    "        for j in range(i+1, DF.shape[1]):\n",
    "            for k in range(j+1, DF.shape[1]):\n",
    "                cX, cY ,cZ = DF.columns[i], DF.columns[j], DF.columns[k]\n",
    "                tmiL.append(min(eSS[cX], eSS[cY], eSS[cZ]))\n",
    "                cxcyczL.append((cX,cY,cZ))\n",
    "    return pd.Series(tmiL, index=cxcyczL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get_max_3v_MIs_for_DF(eDF, eDFc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get_3v_MIs_for_DF(eDF, eDFc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_2v_jEs_for_DF_and_target_field(DF, target_field, cDF=None):\n",
    "    jeDF = get_2v_jEs_for_DF(DF, cDF=cDF).fillna(0)\n",
    "    return (jeDF+jeDF.T)[target_field].drop(target_field)\n",
    "\n",
    "def get_2v_MIs_for_DF_and_target_field(DF, target_field, cDF=None):\n",
    "    eSS = get_Es_for_DF(DF, cDF=cDF) \n",
    "    jeDF =  get_2v_jEs_for_DF_and_target_field(DF, target_field, cDF=cDF)\n",
    "    return pd.Series([eSS[target_field]+eSS[c]-jeDF[c] for c in jeDF.index], index=jeDF.index)\n",
    "\n",
    "def get_3v_jEs_for_DF_and_target_field(DF, target_field, cDF=None):\n",
    "    cL, cDtje = [c for c in DF.columns if c != target_field], {}\n",
    "    for i in range(len(cL)):\n",
    "        cDtje[cL[i]] = [np.NaN]*len(cL)\n",
    "        for j in range(i):\n",
    "            fL = [target_field, cL[i], cL[j]]\n",
    "            if cDF is None:\n",
    "                cDtje[cL[i]][j] = get_jE_for_DF( DF[fL] )\n",
    "            else:\n",
    "                cDtje[cL[i]][j] = get_jE_for_DF( DF[fL], cDF[fL] )                \n",
    "    return pd.DataFrame(cDtje, columns=cL, index=cL)\n",
    "\n",
    "def get_3v_MIs_for_DF_and_target_field(DF, target_field, cDF=None):\n",
    "    eSS = get_Es_for_DF(DF, cDF=cDF)\n",
    "    jeDF = get_2v_jEs_for_DF(DF, cDF=cDF)\n",
    "    tjeDF = get_3v_jEs_for_DF_and_target_field(DF, target_field, cDF=cDF)\n",
    "    tmiDF = pd.DataFrame({c: [np.NaN]*tjeDF.shape[0] for c in tjeDF.columns}, columns=tjeDF.columns, index=tjeDF.index)\n",
    "    t2 = DF.columns.get_loc(target_field)\n",
    "    for i in range(tjeDF.shape[1]):\n",
    "        cX, i2 = tjeDF.columns[i], DF.columns.get_loc(tjeDF.columns[i])\n",
    "        for j in range(i+1, tjeDF.shape[1]):\n",
    "            cY, j2 = tjeDF.columns[j], DF.columns.get_loc(tjeDF.columns[j])\n",
    "            eT, eX, eY = eSS[target_field], eSS[cX], eSS[cY]\n",
    "            jeXY, jeTX, jeTY = jeDF[cY][cX], None, None\n",
    "            if t2 < i2 < j2: jeTX, jeTY = jeDF[cX][target_field], jeDF[cY][target_field]\n",
    "            elif i2 < t2 < j2: jeTX, jeTY = jeDF[target_field][cX], jeDF[cY][target_field]  \n",
    "            elif i2 < j2 < t2: jeTX, jeTY = jeDF[target_field][cX], jeDF[target_field][cY]\n",
    "            tmiDF[cY][cX] = tjeDF[cY][cX]+eT+eX+eY-jeTX-jeTY-jeXY\n",
    "    return tmiDF\n",
    "\n",
    "def get_3v_2WC_info_for_DF_and_target_field(DF, target_field, cDF=None):\n",
    "    jeDF, eT = get_2v_jEs_for_DF(DF, cDF=cDF), None\n",
    "    tjeDF = get_3v_jEs_for_DF_and_target_field(DF, target_field, cDF=cDF)\n",
    "    twcDF = pd.DataFrame({c: [np.NaN]*tjeDF.shape[0] for c in tjeDF.columns}, columns=tjeDF.columns, index=tjeDF.index)\n",
    "    if cDF is None:\n",
    "        eT = get_E_for_SS(DF[target_field])\n",
    "    else:\n",
    "        eT = get_E_for_SS(DF[target_field], cDF[target_field])\n",
    "    for i in range(tjeDF.shape[1]):\n",
    "        for j in range(i+1, tjeDF.shape[1]):\n",
    "            jeUV = jeDF[tjeDF.columns[j]][tjeDF.columns[i]] \n",
    "            jeUVT =tjeDF[tjeDF.columns[j]][tjeDF.columns[i]]\n",
    "            twcDF[tjeDF.columns[j]][tjeDF.columns[i]] = jeUV+eT-jeUVT\n",
    "    return twcDF\n",
    "\n",
    "def get_4v_MIs_for_DF_and_target_field(DF, target_field, cDF=None):\n",
    "    eSS = get_Es_for_DF(DF, cDF=cDF)\n",
    "    jeDF = get_2v_jEs_for_DF(DF, cDF=cDF)\n",
    "    tjeDF = get_3v_jEs_for_DF_and_target_field(DF, target_field, cDF=cDF)\n",
    "    qmiL, cxcucvL = [], []\n",
    "    t2 = DF.columns.get_loc(target_field)\n",
    "    for i in range(tjeDF.shape[1]):\n",
    "        cX, i2 = tjeDF.columns[i], DF.columns.get_loc(tjeDF.columns[i])\n",
    "        for j in range(i+1, tjeDF.shape[1]):\n",
    "            cU, j2 = tjeDF.columns[j], DF.columns.get_loc(tjeDF.columns[j])\n",
    "            for k in range(j+1, tjeDF.shape[1]):\n",
    "                cV, k2 = tjeDF.columns[k], DF.columns.get_loc(tjeDF.columns[k])\n",
    "                eX, eU, eV, eT = eSS[cX], eSS[cU], eSS[cV], eSS[target_field]\n",
    "                jeXU, jeXV, jeUV = jeDF[cU][cX], jeDF[cV][cX], jeDF[cV][cU]\n",
    "                jeXUT, jeXVT, jeUVT = tjeDF[cU][cX], tjeDF[cV][cX], tjeDF[cV][cU]\n",
    "                cL1, cL2 = [cX, cU, cV], [cX, cU, cV, target_field]\n",
    "                if cDF is None:\n",
    "                    jeXUV = get_jE_for_DF(DF[cL1])\n",
    "                    jeXUVT = get_jE_for_DF(DF[cL2])\n",
    "                else:\n",
    "                    jeXUV = get_jE_for_DF(DF[cL1], cDF=cDF[cL1])\n",
    "                    jeXUVT = get_jE_for_DF(DF[cL2], cDF=cDF[cL2])\n",
    "                if t2 < i2 < j2 < k2: jeXT, jeUT, jeVT = jeDF[cX][target_field], jeDF[cU][target_field], jeDF[cV][target_field]\n",
    "                elif i2 < t2 < j2 < k2: jeXT, jeUT, jeVT = jeDF[target_field][cX], jeDF[cU][target_field], jeDF[cV][target_field]\n",
    "                elif i2 < j2 < t2 < k2: jeXT, jeUT, jeVT = jeDF[target_field][cX], jeDF[target_field][cU], jeDF[cV][target_field]\n",
    "                elif i2 < j2 < k2 < t2: jeXT, jeUT, jeVT = jeDF[target_field][cX], jeDF[target_field][cU], jeDF[target_field][cV]\n",
    "                qmi = eX+eU+eV+eT-jeXU-jeXV-jeXT-jeUV-jeUT-jeVT+jeXUV+jeXUT+jeXVT+jeUVT-jeXUVT\n",
    "                qmiL.append(qmi)\n",
    "                cxcucvL.append((cX,cU,cV))\n",
    "    return pd.Series(qmiL, index=cxcucvL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_stepped_cE_data_for_DF(DF, cDF=None, step_count=MAX_STEP_COUNT):\n",
    "    \n",
    "    # FOR EACH COLUMN GET SORTED LIST OF OTHER COLUMNS IN ORDER OF DECREASING MUTUAL INFORMATION\n",
    "    eDF = get_Es_for_DF(DF)\n",
    "    e2DF = get_Es_for_DF(DF, cDF=cDF) if (cDF is not None) else None\n",
    "    miDF = get_2v_MIs_for_DF(DF, cDF).fillna(0)\n",
    "    miDFm = miDF + miDF.T    \n",
    "    cDc2NmiL = {c: sorted(list(miDFm[c].drop(c).items()), reverse=True, key=lambda cNmi: abs(cNmi[1])) for c in miDFm.columns}\n",
    "    \n",
    "    # FOR EACH COLUMN GET step_count LONG LIST OF DECREASING JOINT ENTROPIES, INCREASING CONDITIONAL ENTROPIES\n",
    "    cDc2NmiNceiL, ctDje = {}, {}\n",
    "    for c in DF.columns:\n",
    "        cDc2NmiNceiL[c], e = [], eDF[c]\n",
    "        e2 = e2DF[c] if e2DF is not None else None\n",
    "        for i in range(len(cDc2NmiL[c])):\n",
    "            cL = [cNmi[0] for cNmi in cDc2NmiL[c][:i+1]]\n",
    "            cT1, cT2 = tuple(sorted(cL+[c])), tuple(sorted(cL))\n",
    "            if e2 is None:                \n",
    "                je1=ctDje[cT1]=ctDje[cT1] if cT1 in ctDje else get_jE_for_DF(DF[list(cT1)])\n",
    "                je2=ctDje[cT2]=ctDje[cT2] if cT2 in ctDje else get_jE_for_DF(DF[list(cT2)])\n",
    "            else:\n",
    "                je1=ctDje[cT1]=ctDje[cT1] if cT1 in ctDje else \\\n",
    "                        get_jE_for_DF(DF[list(cT1)], cDF[list(cT1)])\n",
    "                je2=ctDje[cT2]=ctDje[cT2] if cT2 in ctDje else \\\n",
    "                        get_jE_for_DF(DF[list(cT2)], cDF[list(cT2)])\n",
    "            cei = e-(je1-je2) if e2 is None else e2-(je1-je2)\n",
    "            c2, mi = cDc2NmiL[c][i]\n",
    "            if not cDc2NmiNceiL[c] or cei > cDc2NmiNceiL[c][-1][2]:\n",
    "                cDc2NmiNceiL[c].append((c2, mi, cei))\n",
    "            if len(cDc2NmiNceiL[c]) == step_count:    \n",
    "                break\n",
    "        if len(cDc2NmiNceiL[c]) != step_count:\n",
    "            cDc2NmiNceiL[c].extend([cDc2NmiNceiL[c][-1]]*(step_count-len(cDc2NmiNceiL[c])))\n",
    "        cDc2NmiNceiL[c] = cDc2NmiNceiL[c][::-1]\n",
    "                \n",
    "    # RETURN DATAFRAME OF max_count INCREASING CONDITIONAL ENTROPIES FOR EACH COLUMN\n",
    "    return pd.DataFrame(cDc2NmiNceiL, columns=DF.columns).T\n",
    "\n",
    "def get_stepped_cMI_data_for_DF_and_target_field(DF, target_field, cDF=None, \n",
    "            step_count=MAX_STEP_COUNT):\n",
    "    miSS = get_2v_MIs_for_DF_and_target_field(DF, target_field, cDF=cDF)\n",
    "    tmiDF = get_3v_MIs_for_DF_and_target_field(DF, target_field, cDF=cDF).fillna(0)\n",
    "    cDc2NtmiNtmisL, tmiDFm = {}, tmiDF + tmiDF.T\n",
    "    for c in tmiDFm.columns:\n",
    "        c2NtmiL, miXY = list(tmiDFm[c].drop(c).items()), miSS[c]\n",
    "        p_c2NtmiNatmiL =[(c2, tmi, tmi) for c2, tmi in c2NtmiL if tmi >= 0.0]\n",
    "        p_c2NtmiNatmiL.sort(key=lambda c2NtmiNatmi: c2NtmiNatmi[2], reverse=True)\n",
    "        n_c2NtmiNatmiL =[(c2, tmi, -tmi) for c2, tmi in c2NtmiL if tmi < 0.0]\n",
    "        n_c2NtmiNatmiL.sort(key=lambda c2NtmiNatmi: c2NtmiNatmi[2], reverse=True)\n",
    "        cDc2NtmiNtmisL[c] = [(None, 0.0, 0.0)]\n",
    "        for c2, tmi, atmi in p_c2NtmiNatmiL+n_c2NtmiNatmiL:\n",
    "            if cDc2NtmiNtmisL[c][-1][2]+atmi < miXY:\n",
    "                cDc2NtmiNtmisL[c].append((c2, tmi, cDc2NtmiNtmisL[c][-1][2]+atmi))\n",
    "            else:\n",
    "                cDc2NtmiNtmisL[c].append((c2, tmi, miXY))\n",
    "                break\n",
    "        cDc2NtmiNtmisL[c] = cDc2NtmiNtmisL[c][1:]\n",
    "        if len(cDc2NtmiNtmisL[c]) != step_count:\n",
    "            cDc2NtmiNtmisL[c].extend([cDc2NtmiNtmisL[c][-1]]*(step_count-len(cDc2NtmiNtmisL[c])))\n",
    "        cDc2NtmiNtmisL[c] = cDc2NtmiNtmisL[c][:step_count][::-1]\n",
    "    return pd.DataFrame(cDc2NtmiNtmisL, columns=tmiDF.columns).T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test control functions..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _shuffle_DF(DF):\n",
    "    D = {}\n",
    "    for c, L in [(c, list(DF[c])) for c in DF.columns]:\n",
    "        random.shuffle(L)\n",
    "        D[c] = L\n",
    "    return pd.DataFrame(D, DF.index)\n",
    "\n",
    "def _synthesize_by_field_DF(DF):\n",
    "    D = {}\n",
    "    for c, SS in [(c, DF[c]) for c in DF.columns]:\n",
    "        kT, cT = zip(*collect.Counter(SS).items())\n",
    "        D[c] = random.choices(kT, weights=cT, k=SS.size)        \n",
    "        #D[c] = random.choices(kT, k=SS.size)\n",
    "    return pd.DataFrame(D, DF.index)\n",
    "\n",
    "def _join_split_DFs(DF1, DF2):\n",
    "    c1, c2, DF1m, DF2m = DF1.shape[0], DF2.shape[0], DF1, DF2\n",
    "    if c1 < c2:\n",
    "        m, b = c2 // c1, c2 % c1\n",
    "        DF1m = pd.concat([DF1]*m + [DF1.iloc[range(b)]])  \n",
    "    elif c2 < c1:\n",
    "        m, b = c1 // c2, c1 % c2\n",
    "        DF2m = pd.concat([DF2]*m + [DF2.iloc[range(b)]])    \n",
    "    jDF = pd.concat([DF1m, DF2m])    \n",
    "    \n",
    "    rSS = pd.Series([random.choice([True, False]) for i in range(jDF.shape[0])], index=jDF.index)\n",
    "    jsDF1, jsDF2 = jDF.loc[rSS], jDF.loc[~rSS]\n",
    "    jsDF1.index, jsDF2.index = range(jsDF1.shape[0]), range(jsDF2.shape[0])\n",
    "    return jsDF1, jsDF2\n",
    "\n",
    "def _scramble_synthesize_DFs(DF1, DF2):    \n",
    "    C1 = collect.Counter([tuple(vL) for vL in DF1.values.tolist()])\n",
    "    C2 = collect.Counter([tuple(vL) for vL in DF2.values.tolist()])\n",
    "    kL, s1, s2 = list(set(C1.keys()) | set(C2.keys())), sum(C1.values()), sum(C2.values()) \n",
    "    pL = [(C1[k]/s1 + C2[k]/s2)/2.0 for k in kL]\n",
    "    L1 = random.choices(kL, weights=pL, k=max(DF1.size, DF2.size))\n",
    "    L2 = random.choices(kL, weights=pL, k=max(DF1.size, DF2.size))\n",
    "    return pd.DataFrame(L1, columns=DF1.columns), pd.DataFrame(L2, columns=DF1.columns)\n",
    "  \n",
    "def _filter_outliers(SS):\n",
    "    q1, q2, q3 = SS.quantile([.25, .5, .75])\n",
    "    bSS = (q2-(q3-q1)*1.5 <= SS) & (SS < q2+(q3-q1)*1.5)\n",
    "    return SS[bSS], SS[~bSS]\n",
    "        \n",
    "def _get_outlier_filtered_mean_and_stdev(SS, mirror=False):\n",
    "    SS2 = pd.Series(list(np.abs(SS))+list(-np.abs(SS))) if mirror else SS\n",
    "    fSS, _ = _filter_outliers(SS2)\n",
    "    return np.mean(fSS), np.std(fSS)\n",
    "\n",
    "def get_filtered_linear_least_squares_fit(SSx, SSy):\n",
    "    bSS = np.abs(SSy/SSx) <= 100.0\n",
    "    #fSSx, fSSy = SSx[bSS], SSy[bSS]\n",
    "    fSSxy, oSSxy = np.sqrt(SSx**2+SSy**2)[bSS].sort_values(), np.sqrt(SSx**2+SSy**2)[~bSS]\n",
    "    fSSxysl = fSSxy\n",
    "    #fSSxy2, oSSxy2 = fSSxy[fSSxy.size//2:], fSSxy[:fSSxy.size//2]\n",
    "    #fSSxysl, oSSsl = _filter_outliers(SSy[fSSxy2.index]/SSx[fSSxy2.index])\n",
    "    b, m = polyfit(pd.concat([SSx[fSSxysl.index], -SSx[fSSxysl.index]]), \n",
    "                   pd.concat([SSy[fSSxysl.index], -SSy[fSSxysl.index]]), 1)\n",
    "    return b, m, list(fSSxysl.index), list(oSSxy.index)#+list(oSSxy2.index)+list(oSSsl.index)\n",
    "\n",
    "\n",
    "def get_filtered_linear_least_squares_fit2(SSx, SSy):\n",
    "    #SSxy = np.sqrt(SSx**2+SSy**2).sort_values()\n",
    "    #fSSxy, oSSxy = SSxy[SSxy.size//2:], SSxy[:SSxy.size//2]\n",
    "    sSSx = SSx.sort_values()\n",
    "    fSSx, oSSx = sSSx[SSx.size//2:], sSSx[:SSx.size//2]\n",
    "    fSSxsl, oSSsl = _filter_outliers(SSy[fSSx.index]/SSx[fSSx.index])\n",
    "    #b, m = polyfit(SSx[fSSsl.index], SSy[fSSsl.index], 1)\n",
    "    b, m = polyfit(pd.concat([SSx[fSSxsl.index], -SSx[fSSxsl.index]]), \n",
    "                   pd.concat([SSy[fSSxsl.index], -SSy[fSSxsl.index]]), 1)\n",
    "    return b, m, list(fSSxsl.index), list(oSSx.index)+list(oSSsl.index)\n",
    "\n",
    "def _get_Z(SS, dSS=None, mFlag=None):\n",
    "    zSS, dSS = None, (SS if dSS is None else dSS)\n",
    "    if mFlag is None:\n",
    "        mn, std = _get_outlier_filtered_mean_and_stdev(dSS)\n",
    "        zSS = (SS-mn)/std\n",
    "    elif mFlag == 'mirror': \n",
    "        mn, std = _get_outlier_filtered_mean_and_stdev(dSS, mirror=True)\n",
    "        zSS = (SS-mn)/std\n",
    "    elif mFlag == 'dmirror':\n",
    "        mn, std = _get_outlier_filtered_mean_and_stdev(dSS[dSS>=0], mirror=True)\n",
    "        mn2, std2 = _get_outlier_filtered_mean_and_stdev(dSS[dSS<0], mirror=True)\n",
    "        zSS = pd.Series([((v-mn)/std if v >= 0 else (v-mn2)/std2) for v in SS], index=SS.index)\n",
    "    else: raise AssertionError('mFlag is not recognized')\n",
    "    return zSS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(tDF, cDF):\n",
    "    tDFrs, cDFrs = _synthesize_by_field_DF(tDF), _synthesize_by_field_DF(cDF)\n",
    "    tDFjs, cDFjs = _join_split_DFs(tDF, cDF)    \n",
    "\n",
    "    miSStrs, miSScrs, miSSxrs, miSStjs, miSScjs, miSSxjs = None, None, None, None, None, None\n",
    "    if True:\n",
    "        miDFt, miDFc = get_2v_MIs_for_DF(tDF), get_2v_MIs_for_DF(cDF)\n",
    "        miDFx = get_2v_MIs_for_DF(tDF, cDF)\n",
    "        \n",
    "        miDFtmx, miDFcmx = get_max_2v_MIs_for_DF(tDF), get_max_2v_MIs_for_DF(cDF)\n",
    "        \n",
    "        miDFtrs, miDFcrs = get_2v_MIs_for_DF(tDFrs), get_2v_MIs_for_DF(cDFrs)\n",
    "        miDFxrs = get_2v_MIs_for_DF(tDFrs, cDFrs)\n",
    "        miDFtjs, miDFcjs = get_2v_MIs_for_DF(tDFjs), get_2v_MIs_for_DF(cDFjs)\n",
    "        miDFxjs = get_2v_MIs_for_DF(tDFjs, cDFjs)\n",
    "        icL = [(i, c) for c in miDFt for i in miDFt.index if not pd.isna(miDFt[c][i])]\n",
    "        miSSt = pd.Series([v for c in miDFt for v in miDFt[c] if not pd.isna(v)], index=icL)\n",
    "        miSSc = pd.Series([v for c in miDFc for v in miDFc[c] if not pd.isna(v)], index=icL)\n",
    "        miSSx = pd.Series([v for c in miDFx for v in miDFx[c] if not pd.isna(v)], index=icL)\n",
    "        \n",
    "        miSStmx = pd.Series([v for c in miDFtmx for v in miDFtmx[c] if not pd.isna(v)], index=icL)\n",
    "        miSScmx = pd.Series([v for c in miDFcmx for v in miDFcmx[c] if not pd.isna(v)], index=icL)\n",
    "        \n",
    "        miSStrs = pd.Series([v for c in miDFtrs for v in miDFtrs[c] if not pd.isna(v)], index=icL)\n",
    "        miSScrs = pd.Series([v for c in miDFcrs for v in miDFcrs[c] if not pd.isna(v)], index=icL)\n",
    "        miSSxrs = pd.Series([v for c in miDFxrs for v in miDFxrs[c] if not pd.isna(v)], index=icL)\n",
    "        miSStjs = pd.Series([v for c in miDFtjs for v in miDFtjs[c] if not pd.isna(v)], index=icL)\n",
    "        miSScjs = pd.Series([v for c in miDFcjs for v in miDFcjs[c] if not pd.isna(v)], index=icL)\n",
    "        miSSxjs = pd.Series([v for c in miDFxjs for v in miDFxjs[c] if not pd.isna(v)], index=icL)\n",
    "    else:\n",
    "        miSSt, miSSc = get_3v_MIs_for_DF(tDF), get_3v_MIs_for_DF(cDF)\n",
    "        miSSx = get_3v_MIs_for_DF(tDF, cDF)\n",
    "        \n",
    "        miSStmx, miSScmx = get_max_3v_MIs_for_DF(tDF), get_max_3v_MIs_for_DF(cDF)\n",
    "        \n",
    "        miSStrs, miSScrs = get_3v_MIs_for_DF(tDFrs), get_3v_MIs_for_DF(cDFrs)\n",
    "        miSSxrs = get_3v_MIs_for_DF(tDFrs, cDFrs)\n",
    "        miSStjs, miSScjs = get_3v_MIs_for_DF(tDFjs), get_3v_MIs_for_DF(cDFjs)\n",
    "        miSSxjs = get_3v_MIs_for_DF(tDFjs, cDFjs)\n",
    "        \n",
    "        \n",
    "    with plt.rc_context({'xtick.color': 'white', 'ytick.color': 'white', 'text.color': 'white'}):\n",
    "        plt.figure(1, figsize=(12, 18))\n",
    "\n",
    "        \n",
    "        plt.subplot(3, 2, 1)\n",
    "        plt.title('Non-normalized Test vs Control')\n",
    "\n",
    "        #plt.plot(miSStjs, 0.0+1.0*miSStjs, '-', color='green', alpha=0.5)\n",
    "        b1, m1, fL1, oL1 = get_filtered_linear_least_squares_fit(miSSt, miSSc)\n",
    "        plt.plot(miSSt, b1+m1*miSSt, '-', color='blue', alpha=0.5)\n",
    "        #b1js, m1js, fL1js, oL1js = get_filtered_linear_least_squares_fit(miSStjs, miSScjs)\n",
    "        #plt.plot(miSStjs, b1js+m1js*miSStjs, '-', color='red', alpha=0.5)\n",
    "\n",
    "        plt.scatter(miSSt, miSSc, marker='.', alpha=0.5, \n",
    "                    c=pd.Series(range(miSSt.size))/miSSt.size, cmap=plt.get_cmap('tab20'))        \n",
    "        \n",
    "        plt.scatter(miSSt[oL1], miSSc[oL1], marker='.', alpha=1.0, color='red')\n",
    "\n",
    "        \n",
    "        plt.subplot(3, 2, 2)\n",
    "        plt.title('Non-normalized Test vs Cross')\n",
    "        \n",
    "        #lt.plot(miSStjs, 0.0+1.0*miSStjs, '-', color='green', alpha=0.5)\n",
    "        b2, m2, fL2, oL2 = get_filtered_linear_least_squares_fit(miSSt, miSSx)\n",
    "        plt.plot(miSSt, b2+m2*miSSt, '-', color='blue', alpha=0.5)\n",
    "        #2js, m2js, fL2js, oL2js = get_filtered_linear_least_squares_fit(miSStjs, miSSxjs)\n",
    "        #lt.plot(miSStjs, b2js+m2js*miSStjs, '-', color='red', alpha=0.5)\n",
    "\n",
    "        plt.scatter(miSSt, miSSx, marker='.', alpha=0.5, \n",
    "                    c=pd.Series(range(miSSt.size))/miSSt.size, cmap=plt.get_cmap('tab20'))\n",
    "        plt.scatter(miSSt[oL2], miSSx[oL2], marker='.', alpha=1.0, color='red')\n",
    "\n",
    "        plt.subplot(3, 2, 3)\n",
    "        plt.title('Non-normalized Test vs Control (normalized)')\n",
    "        \n",
    "        plt.scatter(miSSt/miSStmx, miSSc/miSScmx, marker='.', alpha=0.5, \n",
    "                    c=pd.Series(range(miSSt.size))/miSSt.size, cmap=plt.get_cmap('tab20'))        \n",
    "        \n",
    "        plt.subplot(3, 2, 4)\n",
    "        plt.title('Non-normalized Test vs Cross (normalized)')\n",
    "        \n",
    "        plt.scatter(miSSt/miSStmx, miSSx, marker='.', alpha=0.5, \n",
    "                    c=pd.Series(range(miSSt.size))/miSSt.size, cmap=plt.get_cmap('tab20'))\n",
    "        \n",
    "        plt.subplot(3, 2, 5)\n",
    "        plt.title('Non-normalized Test vs Control (filtered)')\n",
    "        \n",
    "        #plt.plot(miSStjs, b1js+m1js*miSStjs, '-', color='red', alpha=0.5)\n",
    "        plt.plot(miSSt, b1+m1*miSSt, '-', color='blue', alpha=0.5)\n",
    "        \n",
    "        plt.scatter(miSSt, miSSc, marker='.', alpha=0.5, \n",
    "                    c=pd.Series(range(miSSt.size))/miSSt.size, cmap=plt.get_cmap('tab20'))\n",
    "        plt.scatter(miSStrs, miSScrs, marker='+', alpha=1.0, color='black')        \n",
    "        plt.scatter(miSStjs, miSScjs, marker='+', alpha=1.0, color='gray')\n",
    "        \n",
    "        \n",
    "        plt.subplot(3, 2, 6)\n",
    "        plt.title('Non-normalized Test vs Cross (filtered)')        \n",
    "        \n",
    "        #plt.plot(miSStjs, b2js+m2js*miSStjs, '-', color='red', alpha=0.5)\n",
    "        plt.plot(miSSt, b2+m2*miSSt, '-', color='blue', alpha=0.5)\n",
    "\n",
    "        plt.scatter(miSSt, miSSx, marker='.', alpha=0.5,\n",
    "                    c=pd.Series(range(miSSt.size))/miSSt.size, cmap=plt.get_cmap('tab20'))\n",
    "        plt.scatter(miSStrs, miSSxrs, marker='+', alpha=1.0, color='black')        \n",
    "        plt.scatter(miSStjs, miSSxjs, marker='+', alpha=1.0, color='gray')\n",
    "        \n",
    "    dSS1 = None\n",
    "    return dSS1\n",
    "dSS = test(eDF, eDFc)\n",
    "#print(dSS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Test control functions 2..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def _get_0norm_d_scores(SS):\n",
    "    return SS\n",
    "def _get_0norm_fd_scores(SS, window=5):\n",
    "    vL = [np.NaN]*window//2\n",
    "    vL += [sum(SS[i-window:i]) for i in range(window, SS.size)]        \n",
    "    vL += [np.NaN]*window//2\n",
    "    return pd.Series(nL, index=SS.index)\n",
    "\n",
    "def _get_0norm_k_scores(SS):\n",
    "    return SS\n",
    "\n",
    "def _get_0norm_filtered_SS(SS, \n",
    "                           miSScr, miSStr, miSSxr,\n",
    "                           miSScjs, miSStjs, miSSxjs):\n",
    "    sSS, cL = SS.sort_values(), ['v','vZ','vZd','vZdZ','vZdZp','kZ','kZp']\n",
    "    iL, vNvzNvzdNvzdzNvzdzpNkzNkzpL = [], []\n",
    "    for i, i2 in enumerate(range(10, sSS.size)):\n",
    "        mSS = pd.concat([sSS[:i2], -sSS[:i2]])\n",
    "        v, std, (kz, kzp) = sSS[i], np.std(mSS), stats.kurtosistest(mSS)\n",
    "        vz, vzd = v/std, (v/std-vNvzNvzdNvzdzNvzdzpNkzNkzpL[i-1][1]) if (i > 0) else 0.0\n",
    "        iL.append(i2)\n",
    "        vNvzNvzdNvzdzNvzdzpNkzNkzpL.append((v, v/std, vzd, np.NaN, np.NaN, kz, kzp))\n",
    "    sDF = pd.DataFrame(vNvzNvzdNvzdzNvzdzpNkzNkzpL, index=iL, columns=cL)\n",
    "    zSS = pd.Series((sDF['vZd']-sDF['vZd'].mean())/sDF['vZd'].std(), index=iL)\n",
    "    pSS = pd.Series([(stats.norm.cdf(z) if not np.isnan(z) else np.NaN) for z in zSS], index=iL)\n",
    "    sDF['vZdZ'], sDF['vZdZp'] = zSS, pSS\n",
    "    \n",
    "    print(sDF)\n",
    "\n",
    "    i = sSS.size\n",
    "    scSS1 = _get_0norm_d_scores(sDF['vZ'])\n",
    "    scSS2 = _get_0norm_fd_scores(sDF['vZd'])\n",
    "    scSS3 = _get_0norm_k_scores(sDF['kZ'])\n",
    "    scSS = np.sqrt(scSS1**2+scSS2**2+scSS3**2)\n",
    "    \n",
    "#     if zNiL: i = ([zNiL[-1][1]+1]+[dNi[1] for dNi in dNiL if dNi[1] <= zNiL[-1][1]+1])[-1]\n",
    "#     elif dNiL: i = ([dNi[1] for dNi in dNiL])[-1] \n",
    "\n",
    "    if True:\n",
    "        with plt.rc_context({'xtick.color': 'white', 'ytick.color': 'white', 'text.color': 'white'}):\n",
    "            plt.figure(1, figsize=(18, 18))\n",
    "            plt.subplot(3, 3, 1)\n",
    "            plt.title('stdevs of d from 0')\n",
    "            plt.hist(sDF['vZ'], 20, color='red')\n",
    "            plt.subplot(3, 3, 2)\n",
    "            plt.title(\"stdevs from ave f'(d)\")\n",
    "            plt.hist(sDF['vZdZ'], 20, color='green')\n",
    "            plt.subplot(3, 3, 3)\n",
    "            plt.title(\"kurtosis\")\n",
    "            plt.hist(sDF['kZ'], 20, color='blue')\n",
    "\n",
    "            plt.subplot(3, 3, 4)\n",
    "            plt.title('stdevs of d from 0')\n",
    "            plt.scatter(sDF.index, sDF['vZ'], marker='.', color='red')\n",
    "            plt.subplot(3, 3, 5)\n",
    "            plt.title(\"stdevs from ave f'(d)\")\n",
    "            plt.scatter(sDF.index, sDF['vZdZ'], marker='.', color='green')\n",
    "            plt.subplot(3, 3, 6)\n",
    "            plt.title(\"kurtosis\")\n",
    "            plt.scatter(sDF.index, sDF['kZ'], marker='.', color='blue')\n",
    "\n",
    "            plt.subplot(3, 3, 8)      \n",
    "            plt.title('Non-normalized Test vs Control')\n",
    "            plt.scatter(miSStjs, miSScjs, marker='.', alpha=0.1, color='gray')\n",
    "            plt.scatter(miSStr, miSScr, marker='.', alpha=0.5, color='black')\n",
    "            plt.scatter(miSStr[sSS[:i].index], miSScr[sSS[:i].index], \n",
    "                        marker='.', alpha=1.0, color='blue')\n",
    "\n",
    "            plt.subplot(3, 3, 9)\n",
    "            plt.title('Non-normalized Test vs Cross-Entropy')\n",
    "            plt.scatter(miSStjs, miSSxjs, marker='.', alpha=0.1, color='gray')\n",
    "            plt.scatter(miSStr, miSSxr, marker='.', alpha=0.5, color='black')\n",
    "            plt.scatter(miSStr[sSS[:i].index], miSSxr[sSS[:i].index], \n",
    "                        marker='.', alpha=1.0, color='blue')\n",
    "\n",
    "    return sSS[:i]\n",
    "\n",
    "def test(tDF, cDF):\n",
    "    tDFr, cDFr = _synthesize_by_field_DF(tDF), _synthesize_by_field_DF(cDF)\n",
    "    tDFjs, cDFjs = _join_split_DFs(tDF, cDF)    \n",
    "\n",
    "    miSStr, miSScr, miSSxr = None, None, None\n",
    "    if True:\n",
    "        miDFtr, miDFcr = get_2v_MIs_for_DF(tDFr), get_2v_MIs_for_DF(cDFr)\n",
    "        miDFxr = get_2v_MIs_for_DF(tDFr, cDFr)\n",
    "        miDFtjs, miDFcjs = get_2v_MIs_for_DF(tDFjs), get_2v_MIs_for_DF(cDFjs)\n",
    "        miDFxjs = get_2v_MIs_for_DF(tDFjs, cDFjs)\n",
    "        icL = [(i, c) for c in miDFtr for i in miDFtr.index if not pd.isna(miDFtr[c][i])]\n",
    "        miSStr = pd.Series([v for c in miDFtr for v in miDFtr[c] if not pd.isna(v)], index=icL)\n",
    "        miSScr = pd.Series([v for c in miDFcr for v in miDFcr[c] if not pd.isna(v)], index=icL)\n",
    "        miSSxr = pd.Series([v for c in miDFxr for v in miDFxr[c] if not pd.isna(v)], index=icL)\n",
    "        miSStjs = pd.Series([v for c in miDFtjs for v in miDFtjs[c] if not pd.isna(v)], index=icL)\n",
    "        miSScjs = pd.Series([v for c in miDFcjs for v in miDFcjs[c] if not pd.isna(v)], index=icL)\n",
    "        miSSxjs = pd.Series([v for c in miDFxjs for v in miDFxjs[c] if not pd.isna(v)], index=icL)\n",
    "    if False:\n",
    "        miSStr, miSScr = get_3v_MIs_for_DF(tDFr), get_3v_MIs_for_DF(cDFr)\n",
    "        miSSxr = get_3v_MIs_for_DF(tDFr, cDFr)\n",
    "        miSStjs, miSScjs = get_3v_MIs_for_DF(tDFjs), get_3v_MIs_for_DF(cDFjs)\n",
    "        miSSxjs = get_3v_MIs_for_DF(tDFjs, cDFjs)\n",
    "\n",
    "    dSS_mi0n = _get_0norm_filtered_SS(np.sqrt(miSStr**2+miSScr**2), \n",
    "                                      miSStr, miSScr, miSSxr, \n",
    "                                      miSStjs, miSScjs, miSSxjs)\n",
    "    return dSS_mi0n\n",
    "dSS = test(eDF, eDFc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def get_Z_of_2v_MIs(tDF, cDF):\n",
    "        \n",
    "    miDFt, miDFc = get_2v_MIs_for_DF(tDF), get_2v_MIs_for_DF(cDF)\n",
    "    miDFx = get_2v_MIs_for_DF(tDF, cDF)\n",
    "        \n",
    "    tDFr, cDFr = _synthesize_by_field_DF(tDF), _synthesize_by_field_DF(cDF)\n",
    "    miDFtr, miDFcr = get_2v_MIs_for_DF(tDFr), get_2v_MIs_for_DF(cDFr)\n",
    "    miDFxr = get_2v_MIs_for_DF(tDFr, cDFr)\n",
    "\n",
    "    tDFjs, cDFjs = _join_split_DFs(tDF, cDF)    \n",
    "    miDFtjs, miDFcjs = get_2v_MIs_for_DF(tDFjs), get_2v_MIs_for_DF(cDFjs)\n",
    "    miDFxjs = get_2v_MIs_for_DF(tDFjs, cDFjs)\n",
    "\n",
    "    icL = [(i, c) for c in miDFt for i in miDFt.index if not pd.isna(miDFt[c][i])]\n",
    "    miSSt = pd.Series([v for c in miDFt for v in miDFt[c] if not pd.isna(v)], index=icL)\n",
    "    miSSc = pd.Series([v for c in miDFc for v in miDFc[c] if not pd.isna(v)], index=icL)\n",
    "    miSSx = pd.Series([v for c in miDFx for v in miDFx[c] if not pd.isna(v)], index=icL)\n",
    "    miSStr = pd.Series([v for c in miDFtr for v in miDFtr[c] if not pd.isna(v)], index=icL)\n",
    "    miSScr = pd.Series([v for c in miDFcr for v in miDFcr[c] if not pd.isna(v)], index=icL)\n",
    "    miSSxr = pd.Series([v for c in miDFxr for v in miDFxr[c] if not pd.isna(v)], index=icL)\n",
    "    miSStjs = pd.Series([v for c in miDFtjs for v in miDFtjs[c] if not pd.isna(v)], index=icL)\n",
    "    miSScjs = pd.Series([v for c in miDFcjs for v in miDFcjs[c] if not pd.isna(v)], index=icL)\n",
    "    miSSxjs = pd.Series([v for c in miDFxjs for v in miDFxjs[c] if not pd.isna(v)], index=icL)\n",
    "\n",
    "    zSSt, zSSc = _get_Z(miSSt, mFlag='mirror'), _get_Z(miSSc, mFlag='mirror')\n",
    "    zSSx = _get_Z(miSSx, mFlag='mirror')\n",
    "\n",
    "    zSStr, zSScr = _get_Z(miSStr, miSSt, mFlag='mirror'), _get_Z(miSScr, miSSc, mFlag='mirror')\n",
    "    zSSxr = _get_Z(miSSxr, miSSx, mFlag='mirror')\n",
    "\n",
    "    zSStjs, zSScjs = _get_Z(miSStjs, mFlag='mirror'), _get_Z(miSScjs, mFlag='mirror')\n",
    "    zSSxjs = _get_Z(miSSxjs, mFlag='mirror')\n",
    "\n",
    "    \n",
    "    # DERIVATIVE MI CALCULATIONS\n",
    "    \n",
    "    dSS_mi0n = _get_0norm_filtered_SS(np.sqrt(miSStr**2+miSScr**2))\n",
    "    std_mi0n = np.std(pd.concat([dSS_mi0n, -dSS_mi0n]))\n",
    "    zSStc_mi0n = np.sqrt(miSSt**2+miSSc**2)/std_mi0n\n",
    "    \n",
    "    dSS_z0n = _get_0norm_filtered_SS(np.sqrt(zSStr**2+zSScr**2))\n",
    "    std_z0n = np.std(pd.concat([dSS_z0n, -dSS_z0n]))\n",
    "    zSStc_z0n = np.sqrt(zSSt**2+zSSc**2)/std_z0n\n",
    "    \n",
    "    _process_Z_stuff(miSSt, miSSc, miSSx, miSStr, miSScr, miSSxr, miSStjs, miSScjs, miSSxjs, \n",
    "                     zSSt, zSSc, zSSx, zSStr, zSScr, zSSxr, zSStjs, zSScjs, zSSxjs,\n",
    "                     zSStc_mi0n, zSStc_z0n, dSS_mi0n, dSS_z0n)\n",
    "    #tD = {c: [np.NaN]*miDFt.shape[1] for c in miDFt.columns}\n",
    "    #for i, c in icL: tD[c][miDFt.index.get_loc(i)] = tSS[(i, c)]\n",
    "    #zDF = pd.DataFrame(tD, miDFt.index)\n",
    "    return None\n",
    "\n",
    "def get_Z_of_3v_MIs(tDF, cDF):\n",
    "        \n",
    "    miSSt, miSSc = get_3v_MIs_for_DF(tDF), get_3v_MIs_for_DF(cDF) \n",
    "    miSSx = get_3v_MIs_for_DF(tDF, cDF)\n",
    "\n",
    "    tDFr, cDFr = _synthesize_by_field_DF(tDF), _synthesize_by_field_DF(cDF)\n",
    "    miSStr, miSScr = get_3v_MIs_for_DF(tDFr), get_3v_MIs_for_DF(cDFr)\n",
    "    miSSxr = get_3v_MIs_for_DF(tDFr, cDFr)\n",
    "\n",
    "    tDFjs, cDFjs = _join_split_DFs(tDF, cDF)\n",
    "    miSStjs, miSScjs = get_3v_MIs_for_DF(tDFjs), get_3v_MIs_for_DF(cDFjs)\n",
    "    miSSxjs = get_3v_MIs_for_DF(tDFjs, cDFjs)\n",
    "    \n",
    "    zSSt, zSSc = _get_Z(miSSt, mFlag='mirror'),  _get_Z(miSSc, mFlag='mirror')\n",
    "    zSSx = _get_Z(-miSSx, mFlag='mirror')\n",
    "    \n",
    "    zSStr, zSScr = _get_Z(miSStr, miSSt, mFlag='mirror'),  _get_Z(miSScr, miSSc, mFlag='mirror')\n",
    "    zSSxr = _get_Z(-miSSxr, -miSSx, mFlag='mirror')\n",
    "\n",
    "    zSStjs, zSScjs = _get_Z(miSStjs, miSSt, mFlag='mirror'),  _get_Z(miSScjs, miSSc, mFlag='mirror')\n",
    "    zSSxjs = _get_Z(-miSSxjs, -miSSx, mFlag='mirror')\n",
    "    \n",
    "    \n",
    "    # DERIVATIVE MI CALCULATIONS\n",
    "    \n",
    "    dSS_mi0n = _get_0norm_filtered_SS(np.sqrt(miSStr**2+miSScr**2))\n",
    "    std_mi0n = np.std(pd.concat([dSS_mi0n, -dSS_mi0n]))\n",
    "    zSStc_mi0n = np.sqrt(miSSt**2+miSSc**2)/std_mi0n\n",
    "    \n",
    "    dSS_z0n = _get_0norm_filtered_SS(np.sqrt(zSStr**2+zSScr**2))\n",
    "    std_z0n = np.std(pd.concat([dSS_z0n, -dSS_z0n]))\n",
    "    zSStc_z0n = np.sqrt(zSSt**2+zSSc**2)/std_z0n\n",
    "    \n",
    "    _process_Z_stuff(miSSt, miSSc, -miSSx, miSStr, miSScr, -miSSxr, miSStjs, miSScjs, -miSSxjs, \n",
    "                     zSSt, zSSc, zSSx, zSStr, zSScr, zSSxr, zSStjs, zSScjs, zSSxjs,\n",
    "                     zSStc_mi0n, zSStc_z0n, dSS_mi0n, dSS_z0n)\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "PRINT_PLOTS = True\n",
    "PRINT_TABLE = False\n",
    "    \n",
    "def _process_Z_stuff(miSSt, miSSc, miSSx, miSStr, miSScr, miSSxr, miSStjs, miSScjs, miSSxjs, \n",
    "                     zSSt, zSSc, zSSx, zSStr, zSScr, zSSxr, zSStjs, zSScjs, zSSxjs,\n",
    "                     zSStc_mi0n, zSStc_z0n, dSS_mi0n, dSS_z0n):\n",
    "    \n",
    "    if PRINT_PLOTS:\n",
    "                \n",
    "        fSStc_mi0n = zSStc_mi0n < 2\n",
    "        fSStc_z0n = zSStc_z0n < 2\n",
    "        \n",
    "        mn_mitr, mn_micr = np.mean(miSStr), np.mean(miSScr) \n",
    "        mn_ztr, mn_zcr = np.mean(zSStr), np.mean(zSScr)            \n",
    "        b_mitc, m_mitc = polyfit(miSStjs, miSScjs, 1)            \n",
    "        b_mitx, m_mitx = polyfit(miSStjs, miSSxjs, 1)\n",
    "        b_ztc, m_ztc = polyfit(zSStjs, zSScjs, 1)            \n",
    "        b_ztx, m_ztx = polyfit(zSStjs, zSSxjs, 1)\n",
    "\n",
    "        with plt.rc_context({'xtick.color': 'white', 'ytick.color': 'white', 'text.color': 'white'}):\n",
    "            plt.figure(1, figsize=(18, 30))\n",
    "\n",
    "            ####################################\n",
    "            # NON-NORMALIZED PLOTS\n",
    "\n",
    "            plt.subplot(5, 3, 1)      \n",
    "            plt.title('Non-normalized Test vs Control')\n",
    "            plt.plot(miSSt, b_mitc+m_mitc*miSSt, '-', alpha=0.1, color='red')\n",
    "            plt.scatter(miSStjs, miSScjs, marker='.', alpha=0.1, color='gray')\n",
    "            plt.scatter(miSStr, miSScr, marker='.', alpha=0.5, color='black')\n",
    "            plt.scatter(miSStr[dSS_mi0n.index], miSScr[dSS_mi0n.index], \n",
    "                        marker='.', alpha=1.0, color='blue')\n",
    "\n",
    "#             plt.scatter(miSSt, miSSc, marker='.', alpha=1.0, color='orange')\n",
    "#             for ni, i in enumerate(miSSt[~fSStcr].index):\n",
    "#                 tv, cv =  miSSt[i], miSSc[i]\n",
    "#                 tvjs, cvjs =  miSStjs[i], miSScjs[i]\n",
    "#                 plt.plot([tvjs, tv], [cvjs, cv], '-',  \n",
    "#                          color=plt.get_cmap('tab20')(ni/miSSt[~fSStcr].size), alpha=0.5)\n",
    "#             plt.scatter(miSSt[~fSStcr], miSSc[~fSStcr], marker='.',\n",
    "#                         c=pd.Series(range(miSSt[~fSStcr].size))/miSSt[~fSStcr].size, \n",
    "#                         cmap=plt.get_cmap('tab20'), alpha=1.0)\n",
    "\n",
    "            plt.subplot(5, 3, 2) \n",
    "            plt.title('Non-normalized Test vs Cross-Entropy')        \n",
    "            plt.plot(miSSt, b_mitx+m_mitx*miSSt, '-', alpha=0.1, color='red')\n",
    "            plt.scatter(miSStjs, miSSxjs, marker='.', alpha=0.1, color='gray')\n",
    "            plt.scatter(miSStr, miSSxr, marker='.', alpha=0.5, color='black')\n",
    "            plt.scatter(miSStr[dSS_mi0n.index], miSSxr[dSS_mi0n.index], \n",
    "                        marker='.', alpha=1.0, color='blue')\n",
    "\n",
    "#             plt.scatter(miSSt, miSSx, marker='.', alpha=1.0, color='orange')\n",
    "#             for ni, i in enumerate(miSSt[~fSStcr].index):\n",
    "#                 tv, xv =  miSSt[i], miSSx[i]\n",
    "#                 tvjs, xvjs =  miSStjs[i], miSSxjs[i]\n",
    "#                 plt.plot([tvjs, tv], [xvjs, xv], '-',  \n",
    "#                          color=plt.get_cmap('tab20')(ni/miSSt[~fSStcr].size), alpha=0.5)\n",
    "#             plt.scatter(miSSt[~fSStcr], miSSx[~fSStcr], marker='.',\n",
    "#                         c=pd.Series(range(miSSt[~fSStcr].size))/miSSt[~fSStcr].size, \n",
    "#                         cmap=plt.get_cmap('tab20'), alpha=1.0)\n",
    "\n",
    "\n",
    "            ####################################\n",
    "            # NORMALIZED PLOTS\n",
    "\n",
    "            plt.subplot(5, 3, 4)       \n",
    "            plt.title('Normalized Test vs Control')\n",
    "            plt.plot(zSSt, b_ztc+m_ztc*zSSt, '-', alpha=0.1, color='red')\n",
    "            plt.scatter(zSStjs, zSScjs, marker='.', alpha=0.1, color='gray')\n",
    "            plt.scatter(zSStr, zSScr, marker='.', alpha=0.5, color='black')\n",
    "            plt.scatter(zSStr[dSS_z0n.index], zSScr[dSS_z0n.index], \n",
    "                        marker='.', alpha=1.0, color='blue')\n",
    "\n",
    "#             plt.scatter(zSSt, zSSc, marker='.', alpha=1.0, color='orange')1\n",
    "#             for ni, i in enumerate(zSSt[~fSStcr2].index):\n",
    "#                 tv, cv =  zSSt[i], zSSc[i]\n",
    "#                 tvjs, cvjs =  zSStjs[i], zSScjs[i]\n",
    "#                 plt.plot([tvjs, tv], [cvjs, cv], '-',  \n",
    "#                          color=plt.get_cmap('tab20')(ni/zSSt[~fSStcr2].size), alpha=0.5)\n",
    "#             plt.scatter(zSSt[~fSStcr2], zSSc[~fSStcr2], marker='.',\n",
    "#                         c=pd.Series(range(zSSt[~fSStcr2].size))/zSSt[~fSStcr2].size, \n",
    "#                         cmap=plt.get_cmap('tab20'), alpha=1.0)\n",
    "            \n",
    "            plt.subplot(5, 3, 5)\n",
    "            plt.title('Normalized Test vs Cross-Entropy')\n",
    "            plt.plot(zSSt, b_ztx+m_ztx*zSSt, '-', alpha=0.1, color='red')\n",
    "            plt.scatter(zSStjs, zSSxjs, marker='.', alpha=0.1, color='gray')\n",
    "            plt.scatter(zSStr, zSSxr, marker='.', alpha=0.5, color='black')\n",
    "            plt.scatter(zSStr[dSS_z0n.index], zSSxr[dSS_z0n.index], \n",
    "                        marker='.', alpha=1.0, color='blue')\n",
    "\n",
    "#             plt.scatter(zSSt, zSSx, marker='.', alpha=1.0, color='orange')\n",
    "#             for ni, i in enumerate(zSSt[~fSStcr2].index):\n",
    "#                 tv, xv =  zSSt[i], zSSx[i]\n",
    "#                 tvjs, xvjs =  zSStjs[i], zSSxjs[i]\n",
    "#                 plt.plot([tvjs, tv], [xvjs, xv], '-',  \n",
    "#                          color=plt.get_cmap('tab20')(ni/zSSt[~fSStcr2].size), alpha=0.5)\n",
    "#             plt.scatter(zSSt[~fSStcr2], zSSx[~fSStcr2], marker='.',\n",
    "#                         c=pd.Series(range(zSSt[~fSStcr2].size))/zSSt[~fSStcr2].size, \n",
    "#                         cmap=plt.get_cmap('tab20'), alpha=1.0)\n",
    "\n",
    "\n",
    "            ###############################################\n",
    "            # DISTRIBUTIONS OF DISTANCES FROM RANDOM \n",
    "\n",
    "            plt.subplot(5, 3, 7)\n",
    "            plt.title('Test/control distribution relative to random')\n",
    "            dSSr_mi =  np.sqrt(miSStr**2+miSScr**2)\n",
    "            rSS = pd.Series([random.random() for i in range(miSSt.size)], index=miSSt.index)\n",
    "            plt.scatter(dSSr_mi, rSS, marker='.', alpha=0.5, color='red')\n",
    "            plt.scatter(dSSr_mi[dSS_mi0n.index], rSS[dSS_mi0n.index], \n",
    "                        marker='.', alpha=0.5, color='green')\n",
    "          \n",
    "            plt.subplot(5, 3, 8)\n",
    "            plt.title('Test/control distribution relative to random/ave (hist)')\n",
    "            plt.hist(dSSr_mi, 20, histtype='stepfilled', alpha=0.5, color='red')\n",
    "            plt.hist(dSSr_mi[dSS_mi0n.index], 10, histtype='stepfilled', alpha=0.5, color='green')\n",
    "\n",
    "\n",
    "#             #########################################################################\n",
    "#             # DISTRIBUTIONS OF DISTANCES FROM SCRAMBLED SYNTHETIC (TEST V CONTROL)\n",
    "            \n",
    "#             plt.subplot(5, 3, 10)\n",
    "#             plt.title('Test/control distribution relative to scrambled values')\n",
    "#             dSStcjs = np.sqrt((miSSt-miSStjs)**2 + (miSSc-miSScjs)**2)\n",
    "#             rSS = pd.Series([random.random() for i in range(miSSt.size)], index=miSSt.index)\n",
    "#             plt.scatter(dSStcjs, rSS, marker='.', alpha=0.5,\n",
    "#                         c=pd.Series(range(miSSt.size))/miSSt.size, cmap=plt.get_cmap('tab20'))\n",
    "\n",
    "#             plt.subplot(5, 3, 11)\n",
    "#             plt.title('Test/control distribution relative to scrambled ave')\n",
    "#             dSStcjs2 = np.abs(-1*miSSt + m_mitc*miSSc + b_mitc)/np.sqrt(m_mitc**2 + 1)\n",
    "#             dSStcjs3 = np.abs(-1*miSStjs + m_mitc*miSScjs + b_mitc)/np.sqrt(m_mitc**2 + 1)\n",
    "#             rSS = pd.Series([random.random() for i in range(miSSt.size)], index=miSSt.index)\n",
    "#             plt.scatter(dSStcjs2, rSS, marker='.', alpha=0.5,\n",
    "#                         c=pd.Series(range(miSSt.size))/miSSt.size, cmap=plt.get_cmap('tab20'))\n",
    "                        \n",
    "#             plt.subplot(5, 3, 12)\n",
    "#             plt.title('Test/control distribution relative to scrambled (hist)')\n",
    "#             plt.hist(dSStcjs, 20, histtype='stepfilled', alpha=0.5, color='red')\n",
    "#             plt.hist(dSStcjs2, 20, histtype='stepfilled', alpha=0.5, color='green')\n",
    "#             plt.hist(dSStcjs3, 5, histtype='stepfilled', alpha=0.5, color='blue')\n",
    "            \n",
    "            \n",
    "#             ##################################################################################\n",
    "#             # DISTRIBUTIONS OF DISTANCES FROM SCRAMBLED SYNTHETIC (TEST VS CROSS-ENTROPY)\n",
    "            \n",
    "#             plt.subplot(5, 3, 13)\n",
    "#             plt.title('Test/cross-entropy distribution relative to scrambled values')\n",
    "#             dSStxjs = np.sqrt((miSSt-miSStjs)**2 + (miSSx-miSSxjs)**2)\n",
    "#             rSS = pd.Series([random.random() for i in range(miSSt.size)], index=miSSt.index)\n",
    "#             plt.scatter(dSStxjs, rSS, marker='.', alpha=0.5,\n",
    "#                         c=pd.Series(range(miSSt.size))/miSSt.size, cmap=plt.get_cmap('tab20'))\n",
    "\n",
    "#             plt.subplot(5, 3, 14)\n",
    "#             plt.title('Test/cross-entropy distribution relative to scrambled ave')\n",
    "#             dSStxjs2 = np.abs(-1*miSSt + m_mitx*miSSx + b_mitx)/np.sqrt(m_mitx**2 + 1)\n",
    "#             dSStxjs3 = np.abs(-1*miSStjs + m_mitx*miSSxjs + b_mitx)/np.sqrt(m_mitx**2 + 1)\n",
    "#             rSS = pd.Series([random.random() for i in range(miSSt.size)], index=miSSt.index)\n",
    "#             plt.scatter(dSStxjs2, rSS, marker='.', alpha=0.5,\n",
    "#                         c=pd.Series(range(miSSt.size))/miSSt.size, cmap=plt.get_cmap('tab20'))\n",
    "            \n",
    "#             plt.subplot(5, 3, 15)\n",
    "#             plt.title('Test/cross-entropy distribution relative to scrambled (hist)')\n",
    "#             plt.hist(dSStxjs, 20, histtype='stepfilled', alpha=0.5, color='red')\n",
    "#             plt.hist(dSStxjs2, 20, histtype='stepfilled', alpha=0.5, color='green')\n",
    "#             plt.hist(dSStxjs3, 5, histtype='stepfilled', alpha=0.5, color='blue')\n",
    "\n",
    "    if PRINT_TABLE:\n",
    "        pprint(pd.DataFrame({'zSStcr': zSStcr, 'zzSStcr': zzSStcr}))\n",
    "\n",
    "    return None\n",
    "    \n",
    "get_Z_of_2v_MIs(eDF, eDFc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "get_Z_of_3v_MIs(eDF, eDFc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Presentation constants and utility functions..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def get_scale(total_E, target_radius):\n",
    "    return target_radius/entropy2radii(total_E)\n",
    "\n",
    "def get_color(color, cmap, vmin, vmax): \n",
    "    return cmap((float(color)-float(vmin))/(float(vmax)-float(vmin))) if isinstance(color, numbers.Number) else color\n",
    "\n",
    "def get_graph_center_position(Graph, node_positions):\n",
    "    npL = [node_positions[ni] for ni in Graph.nodes()]\n",
    "    return sum([p[0] for p in npL])/len(npL), sum([p[1] for p in npL])/len(npL)\n",
    "\n",
    "def get_max_radius(Graph, node_positions, center_position):\n",
    "    dxdyL = [(center_position[0]-node_positions[ni][0], center_position[1]-node_positions[ni][1]) for ni in Graph.nodes()]\n",
    "    return max([(dx**2 + dy**2)**0.5 for dx, dy in dxdyL])\n",
    "\n",
    "def get_node_triplets(Graph):\n",
    "    nodes, ntL = list(Graph.nodes()), []\n",
    "    for i in range(len(nodes)):\n",
    "        for j in range(i+1, len(nodes)):\n",
    "            for k in range(j+1, len(nodes)):\n",
    "                ntL.append((nodes[i], nodes[j], nodes[k]))\n",
    "    return ntL\n",
    "\n",
    "def entropy2radii(pdO):\n",
    "    return (np.absolute(pdO)/math.pi)**0.5\n",
    "\n",
    "def entropy2color(pdO):\n",
    "    pdO2 = pdO.fillna(0.0)\n",
    "    return np.sqrt(np.absolute(pdO2))*np.sign(pdO2)\n",
    "    \n",
    "def get_node_letters(Graph, node_positions):\n",
    "    max_v = max(np.absolute([p[0] for p in node_positions.values()] + \\\n",
    "                            [p[1] for p in node_positions.values()]))    \n",
    "    niNnpL = sorted([(ni, node_positions[ni]) for ni in Graph.nodes()], \n",
    "                    key=lambda niNnp: ((max_v-niNnp[1][0])**2+(niNnp[1][1]+max_v)**2)**0.5,\n",
    "                    reverse=True\n",
    "                   )\n",
    "    return dict([(niNnp[0], string.ascii_uppercase[i]) for i, niNnp in enumerate(niNnpL)])    \n",
    "\n",
    "def entropy2iqrcat(pdO):\n",
    "    SS = pd.Series(\n",
    "            [v for c in pdO for v in pdO[c] if not pd.isna(v)] if type(pdO) is pd.DataFrame \\\n",
    "                    else [v for v in pdO if not pd.isna(v)]\n",
    "        )\n",
    "    q1, q2, q3 = SS.quantile([.25, .5, .75])\n",
    "    qL = [-math.inf, q1-3*(q3-q1), q1-1.5*(q3-q1), q1,q2,q3, q3+1.5*(q3-q1), q1+3*(q3-q1), math.inf]\n",
    "    bL = ['out2n', 'out1n', 'qrt1', 'qrt2', 'qrt3', 'qrt4', 'out1p', 'out2p']\n",
    "    SS2 = SS.apply(lambda v: bL[[(qL[i] <= v < qL[i+1]) for i in range(8)].index(True)])\n",
    "    pdO2 = pdO.copy()\n",
    "    if type(pdO) is pd.DataFrame:\n",
    "        cNrL = [(c,r) for c in pdO for r in pdO.index if not pd.isna(pdO[c][r])]\n",
    "        for i, (c, r) in enumerate(cNrL): pdO2.loc[r, c] = SS2[i]\n",
    "    else:\n",
    "        iL = [i for i in pdO.index if not pd.isna(pdO[i])]\n",
    "        for i, i2 in enumerate(iL): pdO2[i2] = SS2[i]\n",
    "    return pdO2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "pairsDF = get_2v_MIs_for_DF(eDFssa)-get_2v_MIs_for_DF(eDFssa, eDFm)\n",
    "print(pairsDF)\n",
    "pairsDF2 = entropy2iqrcat(pairsDF)\n",
    "print(pairsDF2)\n",
    "pairsSS = pd.Series([v for c in pairsDF for v in pairsDF[c] if not pd.isna(v)])\n",
    "pairsSS2 = pd.Series([v for c in pairsDF2 for v in pairsDF2[c] if not pd.isna(v)])\n",
    "plt.hist(pairsSS, 20)\n",
    "#print(pairsSS2)\n",
    "\n",
    "#tripletsSS = get_3v_MIs_for_DF(eDFssa)\n",
    "#print(tripletsSS)\n",
    "#tripletsSS2 = entropy2iqrcat(tripletsSS)\n",
    "#print(tripletsSS2)\n",
    "\n",
    "#plt.hist(tripletsSS, 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "print(pairsSS[pairsSS2=='out2n'])\n",
    "print(pairsSS[pairsSS2=='out1n'])\n",
    "plt.hist(pairsSS[pairsSS2=='out2n'], 1)\n",
    "plt.hist(pairsSS[pairsSS2=='out1n'], 1)\n",
    "plt.hist(pairsSS[pairsSS2=='qrt1'], 2)\n",
    "plt.hist(pairsSS[pairsSS2=='qrt2'], 2)\n",
    "plt.hist(pairsSS[pairsSS2=='qrt3'], 2)\n",
    "plt.hist(pairsSS[pairsSS2=='qrt4'], 2)\n",
    "plt.hist(pairsSS[pairsSS2=='out1p'], 2)\n",
    "plt.hist(pairsSS[pairsSS2=='out2p'], 2)\n",
    "\n",
    "# plt.hist(tripletsSS[tripletsSS2=='n_out'], 12)\n",
    "# plt.hist(tripletsSS[tripletsSS2=='q1'], 6)\n",
    "# plt.hist(tripletsSS[tripletsSS2=='q2'], 3)\n",
    "# plt.hist(tripletsSS[tripletsSS2=='q3'], 3)\n",
    "# plt.hist(tripletsSS[tripletsSS2=='q4'], 6)\n",
    "# plt.hist(tripletsSS[tripletsSS2=='p_out'], 12)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Functions for drawing elements of graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# DRAW TITLE OF GRAPH\n",
    "def draw_title(Graph, axes, node_positions, title_text, font_color='black', font_size=20, font_family='sans-serif', \n",
    "               cmap=None, vmin=None, vmax=None):\n",
    "    cp = get_graph_center_position(Graph, node_positions)\n",
    "    max_r = get_max_radius(Graph, node_positions, cp)\n",
    "    title_xy = cp[0]-max_r*CGRAPH_LABEL_RADIUS_MULTIPLIER, cp[1]+max_r*CGRAPH_LABEL_RADIUS_MULTIPLIER\n",
    "    axes.annotate(title_text, xy=title_xy, fontsize=font_size, va='top', ha='left', family=font_family, color=font_color)\n",
    "    return\n",
    "\n",
    "# DRAW LEGEND OF GRAPH\n",
    "def draw_legend(Graph, axes, node_positions, \n",
    "                size, color='lightgray', \n",
    "                cmap=None, vmin=None, vmax=None, alpha=0.7,\n",
    "                size2=None, color2='gray', \n",
    "                cmap2=None, vmin2=None, vmax2=None, alpha2=0.7,  \n",
    "                size3=None, color3='darkgray', \n",
    "                cmap3=None, vmin3=None, vmax3=None, alpha3=0.7,  \n",
    "                label='', font_size=12, font_family='sans-serif', font_color=FONT_COLOR):\n",
    "    cp = get_graph_center_position(Graph, node_positions)\n",
    "    max_r = get_max_radius(Graph, node_positions, cp)\n",
    "    lgnd_r = max_r*CGRAPH_LEGEND_RADIUS_MULTIPLIER + (max([size, size2, size3]) if size2 else size)     \n",
    "    lgnd_xy = (cp[0]-lgnd_r*math.cos(math.pi/4), cp[1]+lgnd_r*math.sin(math.pi/4))\n",
    "    \n",
    "    if not size2:        \n",
    "        P1 = Circle(lgnd_xy, radius=size, color=get_color(color, cmap, vmin, vmax), alpha=alpha)\n",
    "        axes.add_patch(P1)\n",
    "    else:\n",
    "        P1 = Wedge(lgnd_xy, r=size, \n",
    "           theta1=SPLIT_CIRCLE_ANGLE_0, theta2=SPLIT_CIRCLE_ANGLE_1,\n",
    "           color = get_color(color,cmap,vmin,vmax), alpha=alpha)\n",
    "        axes.add_patch(P1)\n",
    "        P2 = Wedge(lgnd_xy, r=size2, \n",
    "           theta1=SPLIT_CIRCLE_ANGLE_1, theta2=SPLIT_CIRCLE_ANGLE_2,\n",
    "           color = get_color(color2,cmap2,vmin2,vmax2), alpha=alpha2)\n",
    "        axes.add_patch(P2)\n",
    "        P3 = Wedge(lgnd_xy, r=size3, \n",
    "           theta1=SPLIT_CIRCLE_ANGLE_2, theta2=SPLIT_CIRCLE_ANGLE_0,\n",
    "           color = get_color(color3,cmap3,vmin3,vmax3), alpha=alpha3)\n",
    "        axes.add_patch(P3)\n",
    "\n",
    "    lbl_xy = (cp[0]-lgnd_r*math.cos(math.pi/4), cp[1]+lgnd_r*math.sin(math.pi/4))\n",
    "    axes.annotate(label, xy=lbl_xy, fontsize=font_size, va='center', ha='center', \n",
    "                  family=font_family, color=font_color)    \n",
    "    return\n",
    "\n",
    "# DRAW NODES FOR VALUES FOR SINGLETONS\n",
    "def draw_nodes(Graph, axes, node_positions, \n",
    "               sizes=0.01, colors='blue',\n",
    "               cmap=None, vmin=None, vmax=None, alpha=0.7,\n",
    "               sizes2=None, colors2=None,\n",
    "               cmap2=None, vmin2=None, vmax2=None, alpha2=0.7,\n",
    "               sizes3=None, colors3=None,\n",
    "               cmap3=None, vmin3=None, vmax3=None, alpha3=0.7,\n",
    "               with_labels=False, node_labels=None,\n",
    "               font_size=12, font_family='monospace', #'sans-serif', \n",
    "               font_color='black'):\n",
    "    nodes = Graph.nodes()    \n",
    "    sizes = sizes if type(sizes) in (list,pd.Series) else pd.Series([sizes]*len(nodes)) \n",
    "    colors = colors if type(colors) in (list,pd.Series) else pd.Series([colors]*len(nodes))\n",
    "    \n",
    "    if (sizes2 is not None) and not (type(sizes2) in (list,pd.Series) and len(sizes2) == 0):\n",
    "        sizes2 = sizes2 if type(sizes2) in (list,pd.Series) else pd.Series([sizes2]*len(nodes))\n",
    "        colors2 = colors2 if type(colors2) in (list,pd.Series) else pd.Series([colors2]*len(nodes))\n",
    "        sizes3 = sizes3 if type(sizes3) in (list,pd.Series) else pd.Series([sizes3]*len(nodes))\n",
    "        colors3 = colors3 if type(colors3) in (list,pd.Series) else pd.Series([colors3]*len(nodes))\n",
    "    else: \n",
    "        sizes2 = pd.Series([None]*len(nodes))\n",
    "        colors2 = pd.Series([None]*len(nodes))\n",
    "        sizes3 = pd.Series([None]*len(nodes))\n",
    "        colors3 = pd.Series([None]*len(nodes))\n",
    "    \n",
    "    nNsNcNs2Nc2Ns3Nc3L = sorted(list(zip(nodes, sizes, colors, sizes2, colors2, sizes3, colors3)), \n",
    "            key = lambda T: (T[1], T[3], T[5]), reverse=False)\n",
    "    \n",
    "    for ni, s, c, s2, c2, s3, c3 in nNsNcNs2Nc2Ns3Nc3L:\n",
    "        \n",
    "        if not (s2 and c2):\n",
    "            P1 = Circle(node_positions[ni], radius=s, \n",
    "                        color = get_color(c, cmap, vmin, vmax), alpha=alpha)\n",
    "            axes.add_patch(P1)            \n",
    "        else:\n",
    "            P1 = Wedge(node_positions[ni], r=s, \n",
    "                       theta1=SPLIT_CIRCLE_ANGLE_0, theta2=SPLIT_CIRCLE_ANGLE_1,\n",
    "                       color = get_color(c, cmap, vmin, vmax), alpha=alpha)\n",
    "            axes.add_patch(P1)\n",
    "            P2 = Wedge(node_positions[ni], r=s2, \n",
    "                       theta1=SPLIT_CIRCLE_ANGLE_1, theta2=SPLIT_CIRCLE_ANGLE_2,\n",
    "                       color = get_color(c2, cmap2, vmin2, vmax2), alpha=alpha2)\n",
    "            axes.add_patch(P2)\n",
    "            P3 = Wedge(node_positions[ni], r=s3, \n",
    "                       theta1=SPLIT_CIRCLE_ANGLE_2, theta2=SPLIT_CIRCLE_ANGLE_0,\n",
    "                       color = get_color(c3, cmap3, vmin3, vmax3), alpha=alpha3)\n",
    "            axes.add_patch(P3)\n",
    "\n",
    "        if with_labels:   \n",
    "            l, l2 = node_labels[ni][0], node_labels[ni][1:]\n",
    "            axes.annotate(l + ' '*len(l2), xy=node_positions[ni], fontsize=font_size, \n",
    "                          va='center', ha='center', family=font_family,\n",
    "                          color = LETTER_COLOR_DICT[l])\n",
    "            axes.annotate(' ' + l2, xy=node_positions[ni], fontsize=font_size, \n",
    "                          va='center', ha='center', family=font_family, \n",
    "                          color = font_color)            \n",
    "\n",
    "    return\n",
    "\n",
    "\n",
    "# DRAW SLIGHTLY CURVED EDGES FOR VALUES BETWEEN PAIRS\n",
    "\n",
    "def get_edge_offset(node1_position, node2_position, graph_center_position):\n",
    "    n1x, n1y, n2x, n2y, gcx, gcy = *node1_position, *node2_position, *graph_center_position\n",
    "    length = ((n2x-n1x)**2+(n2y-n1y)**2)**0.5\n",
    "    displace_n1 = ((n1x-gcx)**2+(n1y-gcy)**2)**0.5\n",
    "    displace_n2 = ((n2x-gcx)**2+(n2y-gcy)**2)**0.5\n",
    "    acos1 = math.acos((displace_n1**2+displace_n2**2-length**2)/(2*displace_n1*displace_n2))\n",
    "    acos2 = math.acos((displace_n1**2+length**2-displace_n2**2)/(2*displace_n1*length))\n",
    "    incidence = math.pi-0.5*acos1-acos2\n",
    "    return (0.5*math.pi-abs(0.5*math.pi-incidence))/(0.5*math.pi) * EDGE_CURVE_OFFSET_RATIO*length\n",
    "\n",
    "def get_edge_offset_position(node1_position, node2_position, graph_center_position):\n",
    "    n1x, n1y, n2x, n2y, gcx, gcy = *node1_position, *node2_position, *graph_center_position\n",
    "    offset = get_edge_offset(node1_position, node2_position, graph_center_position)\n",
    "    cx, cy = ((n1x+n2x)/2.0, (n1y+n2y)/2.0)    \n",
    "    edge_slope = (n2y-n1y)/(n2x-n1x) if (n2x-n1x) != 0.0 else 1000000.0\n",
    "    orth_angle = math.atan(-1/edge_slope if edge_slope != 0 else 1000000.0)\n",
    "    x_offset, y_offset = offset*math.cos(orth_angle), offset*math.sin(orth_angle)\n",
    "    ox, oy = None, None\n",
    "    if edge_slope >= 0:\n",
    "        if cx >= gcx and cy <= gcy: ox, oy = cx+x_offset, cy+y_offset\n",
    "        elif cx <= gcx and cy >= gcy: ox, oy = cx-x_offset, cy-y_offset\n",
    "        elif cx >= gcx and cy >= gcy:\n",
    "            if edge_slope >= 1: ox, oy = cx+x_offset, cy+y_offset\n",
    "            else: ox, oy = cx-x_offset, cy-y_offset\n",
    "        else:\n",
    "            if edge_slope <= 1: ox, oy = cx+x_offset, cy+y_offset\n",
    "            else: ox, oy = cx-x_offset, cy-y_offset       \n",
    "    else:\n",
    "        if cx >= gcx and cy >= gcy: ox, oy = cx+x_offset, cy+y_offset\n",
    "        elif cx <= gcx and cy <= gcy: ox, oy = cx-x_offset, cy-y_offset\n",
    "        elif cx <= gcx and cy >= gcy:\n",
    "            if edge_slope >= -1: ox, oy = cx+x_offset, cy+y_offset\n",
    "            else: ox, oy = cx-x_offset, cy-y_offset\n",
    "        else:\n",
    "            if edge_slope <= -1: ox, oy = cx+x_offset, cy+y_offset\n",
    "            else: ox, oy = cx-x_offset, cy-y_offset\n",
    "    return (ox, oy)\n",
    "\n",
    "    draw_edges(Graph, ax, node_positions, edge_colors=edge_colors, edge_width=3, \n",
    "               cmap=color_map, vmin=color_min, vmax=color_max)\n",
    "\n",
    "def draw_edges(Graph, axes, node_positions, \n",
    "               colors='blue', width=2, style='-', cmap=None, vmin=None, vmax=None, alpha=1.0,\n",
    "               colors2=None, width2=None, style2='-', cmap2=None, vmin2=None, vmax2=None, alpha2=1.0,\n",
    "               highlights=None, highlight_color=None, highlight_width=2, highlight_style='-'):\n",
    "    edges = Graph.edges()\n",
    "    colors = colors if type(colors) in (list,pd.Series) else [colors]*len(edges)\n",
    "\n",
    "    if (colors2 is not None) and not (type(colors2) in (list,pd.Series) and len(colors2)==0):    \n",
    "        colors2 = colors2 if type(colors2) in (list,pd.Series) else [colors2]*len(edges)\n",
    "    else:\n",
    "        colors2 = [None]*len(edges)   \n",
    "    if (highlights is not None) and not(type(highlights) in (list,pd.Series) and len(highlights)==0):\n",
    "        highlights = highlights if type(highlights) in (list,pd.Series) else [highlights]*len(edges)\n",
    "    else:\n",
    "        highlights = [None]*len(edges)\n",
    "        \n",
    "    cxy = get_graph_center_position(Graph, node_positions)\n",
    "    eNcNc2NhL = sorted(list(zip(edges, colors, colors2, highlights)), \n",
    "                     key=lambda T: (abs(T[1]), (abs(T[2]) if T[2] else None)))   \n",
    "\n",
    "    for (n1i, n2i), c, c2, h in eNcNc2NhL:\n",
    "        if h and (h in HIGHLIGHT_DICT):\n",
    "            n1xy, n2xy = tuple(node_positions[n1i]), tuple(node_positions[n2i])\n",
    "            oxy = get_edge_offset_position(n1xy, n2xy, cxy)\n",
    "            Path = mpath.Path\n",
    "            P = PathPatch(Path([n1xy, oxy, n2xy], [Path.MOVETO, Path.CURVE3, Path.CURVE3]),\n",
    "                           color=highlight_color if highlight_color else HIGHLIGHT_DICT[h], \n",
    "                           linewidth=highlight_width, linestyle=highlight_style,\n",
    "                           transform=axes.transData, fc='None', alpha=1.0\n",
    "                        )\n",
    "            axes.add_patch(P)        \n",
    "\n",
    "    for (n1i, n2i), c, c2, h in eNcNc2NhL:\n",
    "        n1xy, n2xy = tuple(node_positions[n1i]), tuple(node_positions[n2i])\n",
    "        oxy = get_edge_offset_position(n1xy, n2xy, cxy)\n",
    "        Path = mpath.Path\n",
    "        if not c2:\n",
    "            P1 = PathPatch(Path([n1xy, oxy, n2xy], [Path.MOVETO, Path.CURVE3, Path.CURVE3]),\n",
    "                           color = get_color(c, cmap, vmin, vmax), \n",
    "                           linewidth=width, linestyle=style, \n",
    "                           transform=axes.transData, fc='None', alpha=alpha\n",
    "                        )\n",
    "            axes.add_patch(P1)\n",
    "        else:\n",
    "            clr1, clr2, w1, a1, w2, a2 = None, None, None, None, None, None\n",
    "            if width > width2:\n",
    "                clr1, clr2 = get_color(c, cmap, vmin, vmax), get_color(c2, cmap2, vmin2, vmax2)\n",
    "                w1, a1, w2, a2 = width, alpha, width2, alpha2\n",
    "            else:\n",
    "                clr1, clr2 = get_color(c2, cmap2, vmin2, vmax2), get_color(c, cmap, vmin, vmax)\n",
    "                w1, a1, w2, a2 = width2, alpha2, width, alpha\n",
    "            P1 = PathPatch(Path([n1xy, oxy, n2xy], [Path.MOVETO, Path.CURVE3, Path.CURVE3]),\n",
    "                              color = clr1, linewidth=w1, linestyle=style, \n",
    "                              transform=axes.transData, fc='None', alpha=a1\n",
    "                            )\n",
    "            axes.add_patch(P1)\n",
    "            P2 = PathPatch(Path([n1xy, oxy, n2xy], [Path.MOVETO, Path.CURVE3, Path.CURVE3]),\n",
    "                              color = clr2, linewidth=w2, linestyle=style2, \n",
    "                              transform=axes.transData, fc='None', alpha=a2\n",
    "                            )\n",
    "            axes.add_patch(P2)\n",
    "            \n",
    "    return\n",
    "\n",
    "\n",
    "# DRAW LABELED OUTCIRCLE AND REFERENCE LINES\n",
    "\n",
    "def get_outcircle_angles(node_positions):\n",
    "    nc = len(node_positions)\n",
    "    ec = int(math.factorial(nc)/(math.factorial(3)*math.factorial(nc-3)))\n",
    "    return [i*(2*math.pi)/ec for i in range(ec)]\n",
    "        \n",
    "def get_outcircle_positions(center_position, max_radius, outcircle_angles):\n",
    "    radius = max_radius * CGRAPH_RADIUS_MULTIPLIER\n",
    "    return [(center_position[0]+radius*math.cos(a), center_position[1]+radius*math.sin(a)) for a in outcircle_angles]\n",
    "\n",
    "def get_outcircle_label_positions(center_position, max_radius, outcircle_angles):\n",
    "    radius = max_radius * CGRAPH_LABEL_RADIUS_MULTIPLIER\n",
    "    return [(center_position[0]+radius*math.cos(a), center_position[1]+radius*math.sin(a)) for a in outcircle_angles]\n",
    "                \n",
    "def get_outcircle_triplet_coordinate_info(Graph, node_positions, node_triplets):\n",
    "    center_position = get_graph_center_position(Graph, node_positions)\n",
    "    apL, dpL, dhL, aL = [], [], [], []\n",
    "    for nitT in node_triplets:\n",
    "        np1, np2, np3 = node_positions[nitT[0]], node_positions[nitT[1]], node_positions[nitT[2]]\n",
    "        mx, my = ((np1[0]+np2[0]+np3[0])/3.0, (np1[1]+np2[1]+np3[1])/3.0) \n",
    "        dmx, dmy = mx-center_position[0], my-center_position[1]\n",
    "        dmh = (dmx**2+dmy**2)**0.5\n",
    "        acos = math.acos(dmx/dmh)\n",
    "        a = acos if dmy >= 0 else 2*math.pi-acos\n",
    "        apL.append((mx, my))\n",
    "        dpL.append((dmx, dmy))\n",
    "        dhL.append(dmh)\n",
    "        aL.append(a)\n",
    "    return pd.DataFrame({'abs_position': apL, 'diff_position': dpL, 'diff_hypotenuse': dhL, 'angle': aL},  index = node_triplets)\n",
    "\n",
    "def assign_outcircle_positions(Graph, node_positions, node_sizes, triplet_coordinate_info):\n",
    "\n",
    "    center_position = get_graph_center_position(Graph, node_positions)\n",
    "    max_radius = get_max_radius(Graph, node_positions, center_position)\n",
    "    outcircle_angles = get_outcircle_angles(node_positions) \n",
    "    outcircle_positions = get_outcircle_positions(center_position, max_radius, outcircle_angles)\n",
    "    outcircle_label_positions = get_outcircle_label_positions(center_position, max_radius, outcircle_angles)\n",
    "    \n",
    "    node_triplets = get_node_triplets(Graph)\n",
    "    tNsL = sorted(zip(node_triplets, node_sizes), key=lambda tNs: tNs[1], reverse=True)\n",
    "    \n",
    "    nodes, outcircle_count = list(Graph.nodes()), len(outcircle_angles)\n",
    "    tripletL, tposL = [None]*outcircle_count, [None]*outcircle_count\n",
    "    for nitT in [tNs[0] for tNs in tNsL]:\n",
    "        a, tpos = triplet_coordinate_info['angle'][nitT], triplet_coordinate_info['abs_position'][nitT]\n",
    "        si = int(round((a/(2*math.pi))*outcircle_count))\n",
    "        if si == outcircle_count: si = 0\n",
    "        for ci in range(outcircle_count):\n",
    "            di, dd = int((ci+1)//2), bool((ci+1)%2)\n",
    "            i = si+di if dd else si-di\n",
    "            if i < 0: i = outcircle_count-(-i)\n",
    "            elif i >= outcircle_count: i = i-outcircle_count\n",
    "            if not tripletL[i]:\n",
    "                tripletL[i], tposL[i] = nitT, tpos\n",
    "                break\n",
    "                \n",
    "    return pd.DataFrame({'angle': outcircle_angles, 'position': outcircle_positions, 'triplet_position': tposL, \n",
    "                         'label_position': outcircle_label_positions}, index=tripletL)\n",
    "    \n",
    "def draw_outcircle(Graph, axes, node_positions, \n",
    "                   sizes=0.005, colors='blue', width=0.5, style='-',\n",
    "                   cmap=None, vmin=None, vmax=None, alpha=1.0,\n",
    "                   sizes2=None, colors2=None, \n",
    "                   cmap2=None, vmin2=None, vmax2=None, alpha2=1.0,\n",
    "                   sizes3=None, colors3=None, \n",
    "                   cmap3=None, vmin3=None, vmax3=None, alpha3=1.0,\n",
    "                   highlights=None, highlight_color=None, highlight_width=0.5, highlight_style='-',\n",
    "                   node_letters=None,  \n",
    "                   font_color='darkgray', font_size=10, font_family='monospace'):\n",
    "\n",
    "    triplets = get_node_triplets(Graph)\n",
    "    sizes = sizes if type(sizes) in (list,pd.Series) else pd.Series([sizes]*len(triplets))\n",
    "    colors = colors if type(colors) in (list,pd.Series) else pd.Series([colors]*len(triplets))\n",
    "    if (highlights is not None) and not(type(highlights) in (list,pd.Series) and len(highlights)==0):\n",
    "        highlights=highlights if type(highlights) in (list,pd.Series) else [highlights]*len(triplets)\n",
    "    else:\n",
    "        highlights = [None]*len(triplets)\n",
    "    \n",
    "    if sizes2 is not None and colors2 is not None:\n",
    "        sizes2 = sizes2 if type(sizes2) in (list,pd.Series) else pd.Series([sizes2]*len(triplets))\n",
    "        colors2=colors2 if type(colors2) in (list,pd.Series) else pd.Series([colors2]*len(triplets))\n",
    "        sizes3 = sizes3 if type(sizes3) in (list,pd.Series) else pd.Series([sizes3]*len(triplets))\n",
    "        colors3=colors3 if type(colors3) in (list,pd.Series) else pd.Series([colors3]*len(triplets))\n",
    "\n",
    "    else: \n",
    "        sizes2 = pd.Series([None]*len(triplets))\n",
    "        colors2 = pd.Series([None]*len(triplets))\n",
    "        sizes3 = pd.Series([None]*len(triplets))\n",
    "        colors3 = pd.Series([None]*len(triplets))\n",
    "        \n",
    "    tripletDF = get_outcircle_triplet_coordinate_info(Graph, node_positions, triplets)\n",
    "    assignedDF = assign_outcircle_positions(Graph, node_positions, sizes, tripletDF)\n",
    "    tNsNcNs2Nc2Ns3Nc3NhL = sorted(\n",
    "            list(zip(triplets, sizes, colors, sizes2, colors2, sizes3, colors3, highlights)),\n",
    "                    key = lambda T: (T[1], T[3], T[5]), reverse=False\n",
    "        )\n",
    "    \n",
    "    for niT, s, c, s2, c2, s3, c3, h in tNsNcNs2Nc2Ns3Nc3NhL:\n",
    "        if h and (h in HIGHLIGHT_DICT): \n",
    "            oc_xy, t_xy = assignedDF['position'][niT], assignedDF['triplet_position'][niT]\n",
    "            for n_xy in [node_positions[ni] for ni in niT]:\n",
    "                Path = mpath.Path            \n",
    "                P = PathPatch(Path([n_xy, oc_xy], [Path.MOVETO, Path.LINETO]),\n",
    "                               color=highlight_color if highlight_color else HIGHLIGHT_DICT[h],\n",
    "                               linewidth=highlight_width, linestyle=highlight_style,\n",
    "                               transform=axes.transData, fc='None', alpha=1.0\n",
    "                            )\n",
    "                axes.add_patch(P)    \n",
    "    for niT, s, c, s2, c2, s3, c3, h in tNsNcNs2Nc2Ns3Nc3NhL:\n",
    "        oc_xy, t_xy = assignedDF['position'][niT], assignedDF['triplet_position'][niT]\n",
    "        for n_xy in [node_positions[ni] for ni in niT]:\n",
    "            Path = mpath.Path            \n",
    "            P1 = PathPatch(Path([n_xy, oc_xy], [Path.MOVETO, Path.LINETO]),\n",
    "                           color = get_color(c, cmap, vmin, vmax), \n",
    "                           linewidth=width, linestyle=style,\n",
    "                           transform=axes.transData, fc='None', alpha=alpha\n",
    "                        )\n",
    "            axes.add_patch(P1)\n",
    "        if not (s2 and c2):\n",
    "            P3 = Circle(oc_xy, radius=s, color = get_color(c, cmap, vmin, vmax), alpha=alpha)\n",
    "            axes.add_patch(P3)            \n",
    "        else:\n",
    "            P3 = Wedge(oc_xy, r=s, \n",
    "                       theta1=SPLIT_CIRCLE_ANGLE_0, theta2=SPLIT_CIRCLE_ANGLE_1,\n",
    "                       color = get_color(c,cmap,vmin,vmax), alpha=alpha)\n",
    "            axes.add_patch(P3)\n",
    "            P4 = Wedge(oc_xy, r=s2, \n",
    "                       theta1=SPLIT_CIRCLE_ANGLE_1, theta2=SPLIT_CIRCLE_ANGLE_2,\n",
    "                       color = get_color(c2,cmap2,vmin2,vmax2), alpha=alpha2)\n",
    "            axes.add_patch(P4)\n",
    "            P5 = Wedge(oc_xy, r=s3, \n",
    "                       theta1=SPLIT_CIRCLE_ANGLE_2, theta2=SPLIT_CIRCLE_ANGLE_0,\n",
    "                       color = get_color(c3,cmap3,vmin3,vmax3), alpha=alpha3)\n",
    "            axes.add_patch(P5)\n",
    "        if node_letters:\n",
    "            lbl_xy, lbl_a = assignedDF['label_position'][niT], assignedDF['angle'][niT]\n",
    "            if math.pi/2.0 <lbl_a < 3*math.pi/2.0: lbl_a += math.pi\n",
    "            lL = sorted([node_letters[ni] for ni in niT])\n",
    "            for i in range(3):\n",
    "                l = lL[i]\n",
    "                lbl, tc = ' '*i + l + ' '*(2-i), LETTER_COLOR_DICT[l]\n",
    "                axes.annotate(lbl, xy=lbl_xy, fontsize=font_size, ha='center', \n",
    "                              family=font_family, color=tc,\n",
    "                              rotation=math.degrees(lbl_a)) \n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#plt.cm.binary(np.linspace(0., 1, 128))\n",
    "#plt.get_cmap(ENTROPY_CMAP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Function to render a graph representing the entropy distribution of the table..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def render_entropy_graph(DF, cDF=None, target_field=None, outfile=None):\n",
    "    \n",
    "    # GET ENTROPY, CROSS ENTROPY(?), MUTUAL INFORMATION TO BE VISUALIZED\n",
    "    \n",
    "    legendValue, legendValue2 = None, None\n",
    "    scale, title, label = None, None, None\n",
    "    singletonsSS, steppedSingletonsDF, steppedSingletonsDF_color = None, None, None\n",
    "    pairsDF, tripletsSS = None, None\n",
    "    singletons2SS, steppedSingletons2DF, steppedSingletons2DF_color = None, None, None \n",
    "    pairs2DF, triplets2SS = None, None\n",
    "    Graph, nodePositions = None, None\n",
    "    if not target_field:\n",
    "        \n",
    "        legendValue = te = get_jE_for_DF(DF)\n",
    "        scale = get_scale(te, RADIUS_FOR_TOTAL_ENTROPY)\n",
    "        title, label = GRAPH_TITLE, GRAPH_DATASET_LABEL % (te)\n",
    "        singletonsSS = get_Es_for_DF(DF)\n",
    "        sceDF = get_stepped_cE_data_for_DF(DF)\n",
    "        imiDF, ceiDF = sceDF.applymap(lambda T: T[1]), sceDF.applymap(lambda T: T[2])\n",
    "        steppedSingletonsDF, steppedSingletonsDF_color = ceiDF, -imiDF\n",
    "        pairsDF = -get_2v_MIs_for_DF(DF)\n",
    "        tripletsSS = -get_3v_MIs_for_DF(DF)\n",
    "\n",
    "        if cDF is not None:\n",
    "            \n",
    "            legendValue2 = te2 = get_jE_for_DF(DF, cDF=cDF)\n",
    "            scale = get_scale(max([te, te2]), RADIUS_FOR_TOTAL_ENTROPY)\n",
    "            singletons2SS = get_Es_for_DF(DF, cDF=cDF)\n",
    "            sce2DF = get_stepped_cE_data_for_DF(DF, cDF=cDF)\n",
    "            imi2DF, cei2DF = sce2DF.applymap(lambda T: T[1]), sce2DF.applymap(lambda T: T[2])\n",
    "            steppedSingletons2DF, steppedSingletons2DF_color = cei2DF, -imi2DF\n",
    "            pairs2DF = -get_2v_MIs_for_DF(DF, cDF=cDF)\n",
    "            triplets2SS = -get_3v_MIs_for_DF(DF, cDF=cDF)\n",
    "            \n",
    "            legendValue3 = te3 = get_jE_for_DF(cDF)\n",
    "            scale = get_scale(max([te, te2, te3]), RADIUS_FOR_TOTAL_ENTROPY)\n",
    "            singletons3SS = get_Es_for_DF(cDF)\n",
    "            sce3DF = get_stepped_cE_data_for_DF(cDF)\n",
    "            imi3DF, cei3DF = sce3DF.applymap(lambda T: T[1]), sce3DF.applymap(lambda T: T[2])\n",
    "            steppedSingletons3DF, steppedSingletons3DF_color = cei3DF, -imi3DF\n",
    "            pairs3DF = -get_2v_MIs_for_DF(cDF)\n",
    "            triplets3SS = -get_3v_MIs_for_DF(cDF)\n",
    "            \n",
    "        ewDF = get_2v_MIs_for_DF(DF)\n",
    "        ewDF1 = (ewDF-(ewDF.min().min())).fillna(0)\n",
    "        G1 = nx.from_numpy_matrix(np.matrix(ewDF1))\n",
    "        np1 = nx.spring_layout(G1, iterations=10000)\n",
    "        ewDF2 = (np.absolute(ewDF.fillna(0))**(1))*np.sign(ewDF.fillna(0))\n",
    "        Graph = nx.from_numpy_matrix(np.matrix(ewDF2))\n",
    "        nodePositions = nx.spring_layout(Graph, iterations=10000, pos=np1)\n",
    "                         \n",
    "    else:\n",
    "        pass\n",
    "       \n",
    "    # TRANSLATE ENTROPY, CROSS ENTROPY(?), MUTUAL INFORMATION INTO ELEMENTS OF THE GRAPH\n",
    "    \n",
    "    fields, steps = steppedSingletonsDF.index, steppedSingletonsDF.columns\n",
    "    legendRadius= entropy2radii(legendValue)*scale\n",
    "    bgRadiiSS = entropy2radii(singletonsSS)*scale\n",
    "    nodeRadiiDF = entropy2radii(steppedSingletonsDF)*scale    \n",
    "    tripletRadiiSS = entropy2radii(tripletsSS)*scale\n",
    "    bgNodeColorSS = entropy2color(singletonsSS)\n",
    "    nodeColorDF = entropy2color(steppedSingletonsDF_color)\n",
    "    edgeColorDF = entropy2color(pairsDF)\n",
    "    tripletColorSS = entropy2color(tripletsSS)\n",
    "    nodeLettersD = get_node_letters(Graph, nodePositions)\n",
    "    nodeLabelsD = dict([(i, \"%s: %s\" % (nodeLettersD[i], fields[i])) for i in range(len(fields))])\n",
    "    \n",
    "    bgNodeColorL = [bgNodeColorSS[fields[i]] for i in Graph.nodes()]\n",
    "    ncL = [nodeColorDF[c][fields[i]] for c in nodeColorDF.columns for i in Graph.nodes()]    \n",
    "    edgeColorL = [edgeColorDF[fields[i2]][fields[i1]] for (i1,i2) in Graph.edges()]\n",
    "    tripletColorL = [tripletColorSS[(fields[i1],fields[i2],fields[i3])] \\\n",
    "                     for (i1,i2,i3) in get_node_triplets(Graph)]\n",
    "                   \n",
    "    legendRadius2, bgRadii2SS, nodeRadii2DF, tripletRadii2SS = None, None, None, None\n",
    "    bgNodeColor2SS, nodeColor2DF, edgeColor2DF, tripletColor2SS = None, None, None, None\n",
    "    bgNodeColor2L, edgeColor2L, tripletColor2L = [], [], []\n",
    "\n",
    "    legendRadius3, bgRadii3SS, nodeRadii3DF, tripletRadii3SS = None, None, None, None\n",
    "    bgNodeColor3SS, nodeColor3DF, edgeColor3DF, tripletColor3SS = None, None, None, None\n",
    "    bgNodeColor3L, edgeColor3L, tripletColor3L = [], [], []\n",
    "    edgeHighlightDF, tripletHighlightSS = None, None\n",
    "    edgeHighlightL, tripletHighlightL = [], []\n",
    "\n",
    "    if cDF is not None:        \n",
    "        legendRadius2 = entropy2radii(legendValue2)*scale\n",
    "        bgRadii2SS = entropy2radii(singletons2SS)*scale\n",
    "        nodeRadii2DF = entropy2radii(steppedSingletons2DF)*scale    \n",
    "        tripletRadii2SS = entropy2radii(triplets2SS)*scale\n",
    "        bgNodeColor2SS = entropy2color(singletons2SS)\n",
    "        nodeColor2DF = entropy2color(steppedSingletons2DF_color)\n",
    "        edgeColor2DF = entropy2color(pairs2DF)\n",
    "        tripletColor2SS = entropy2color(triplets2SS)        \n",
    "        bgNodeColor2L = [bgNodeColor2SS[fields[i]] for i in Graph.nodes()]\n",
    "        edgeColor2L = [edgeColor2DF[fields[i2]][fields[i1]] for (i1,i2) in Graph.edges()] \n",
    "        tripletColor2L = [tripletColor2SS[(fields[i1],fields[i2],fields[i3])] \\\n",
    "                          for (i1,i2,i3) in get_node_triplets(Graph)]  \n",
    "        \n",
    "        legendRadius3 = entropy2radii(legendValue3)*scale\n",
    "        bgRadii3SS = entropy2radii(singletons3SS)*scale\n",
    "        nodeRadii3DF = entropy2radii(steppedSingletons3DF)*scale\n",
    "        tripletRadii3SS = entropy2radii(triplets3SS)*scale\n",
    "        bgNodeColor3SS = entropy2color(singletons3SS)\n",
    "        nodeColor3DF = entropy2color(steppedSingletons3DF_color)\n",
    "        edgeColor3DF = entropy2color(pairs3DF)\n",
    "        tripletColor3SS = entropy2color(triplets3SS)\n",
    "        bgNodeColor3L = [bgNodeColor3SS[fields[i]] for i in Graph.nodes()]\n",
    "        edgeColor3L = [edgeColor3DF[fields[i2]][fields[i1]] for (i1,i2) in Graph.edges()] \n",
    "        tripletColor3L = [tripletColor3SS[(fields[i1],fields[i2],fields[i3])] \\\n",
    "                          for (i1,i2,i3) in get_node_triplets(Graph)]  \n",
    "        \n",
    "        \n",
    "        edgeHighlightDF = entropy2iqrcat(pairsDF-pairs2DF)\n",
    "        tripletHighlightSS = entropy2iqrcat(tripletsSS-triplets2SS)\n",
    "        edgeHighlightL = [edgeHighlightDF[fields[i2]][fields[i1]] for (i1,i2) in Graph.edges()] \n",
    "        tripletHighlightL = [tripletHighlightSS[(fields[i1],fields[i2],fields[i3])] \\\n",
    "                             for (i1,i2,i3) in get_node_triplets(Graph)]\n",
    "        \n",
    "    ac2A = np.absolute(ncL + edgeColorL + tripletColorL + bgNodeColorL + \\\n",
    "                       edgeColor2L + tripletColor2L + bgNodeColor2L + \\\n",
    "                       edgeColor3L + tripletColor3L + bgNodeColor3L)\n",
    "    colorMin, colorMax = -max(ac2A), max(ac2A)\n",
    "        \n",
    "    # DRAW GRAPH\n",
    "        \n",
    "    fig = plt.figure(num=None, figsize=(GRAPH_WIDTH, GRAPH_HEIGHT), dpi=GRAPH_DOTS_PER_INCH)\n",
    "    ax = plt.gca()\n",
    "    ax.set_facecolor(BACKGROUND_COLOR)\n",
    "    plt.tick_params(axis='both', which='both', bottom=False, top=False, \n",
    "                    labelbottom=False, labelleft=False)\n",
    "    plt.axis('equal')\n",
    "    #plt.rc('text', usetex=True)\n",
    "    \n",
    "    draw_title(Graph, ax, nodePositions, title, font_color=FONT_COLOR)\n",
    "    \n",
    "    draw_legend(Graph, ax, nodePositions,                 \n",
    "                size=legendRadius, color=colorMax*0.9, \n",
    "                cmap=ENTROPY_CMAP, vmin=colorMin, vmax=colorMax, alpha=0.9,\n",
    "                size2=legendRadius2, color2=colorMax, \n",
    "                cmap2=ENTROPY_CMAP, vmin2=colorMin, vmax2=colorMax, alpha2=0.9,\n",
    "                size3=legendRadius3, color3=colorMax*0.9, \n",
    "                cmap3=ENTROPY_CMAP, vmin3=colorMin, vmax3=colorMax, alpha3=0.9,\n",
    "                label=label, font_color=FONT_COLOR)\n",
    "        \n",
    "    draw_outcircle(Graph, ax, nodePositions, \n",
    "                   sizes=tripletRadiiSS, colors=tripletColorL, width=1,\n",
    "                   cmap=ENTROPY_CMAP2, vmin=colorMin, vmax=colorMax, alpha=1.0,\n",
    "                   sizes2=tripletRadii2SS, colors2=tripletColor2L,\n",
    "                   cmap2=ENTROPY_CMAP2, vmin2=colorMin, vmax2=colorMax, alpha2=1.0,\n",
    "                   sizes3=tripletRadii3SS, colors3=tripletColor3L,\n",
    "                   cmap3=ENTROPY_CMAP2, vmin3=colorMin, vmax3=colorMax, alpha3=1.0,\n",
    "                   highlights=tripletHighlightL, highlight_width=2,\n",
    "                   node_letters=nodeLettersD, font_color=FONT_COLOR)\n",
    "    \n",
    "    draw_nodes(Graph, ax, nodePositions, \n",
    "               sizes=bgRadiiSS, colors=bgNodeColorL, \n",
    "               cmap=ENTROPY_CMAP, vmin=colorMin, vmax=colorMax, alpha=0.9,\n",
    "               sizes2=bgRadii2SS, colors2=bgNodeColor2L, \n",
    "               cmap2=ENTROPY_CMAP, vmin2=colorMin, vmax2=colorMax, alpha2=0.9,\n",
    "               sizes3=bgRadii3SS, colors3=bgNodeColor3L, \n",
    "               cmap3=ENTROPY_CMAP, vmin3=colorMin, vmax3=colorMax, alpha3=0.9,\n",
    "               with_labels=False)\n",
    "    \n",
    "    draw_edges(Graph, ax, nodePositions, \n",
    "               colors=edgeColorL, width=3, \n",
    "               cmap=ENTROPY_CMAP2, vmin=colorMin, vmax=colorMax, alpha=1.0,\n",
    "               colors2=edgeColor2L, width2=2, \n",
    "               cmap2=ENTROPY_CMAP2, vmin2=colorMin, vmax2=colorMax, alpha2=1.0,\n",
    "               highlights=edgeHighlightL, highlight_width=5)\n",
    "        \n",
    "    for i, step in enumerate(steps):\n",
    "        draw_nodes(Graph, ax, nodePositions, \n",
    "                   sizes=nodeRadiiDF[step], \n",
    "                   colors=nodeColorDF[step], \n",
    "                   cmap=ENTROPY_CMAP2, vmin=colorMin, vmax=colorMax, alpha=1.0,\n",
    "                   sizes2=nodeRadii2DF[step] if nodeRadii2DF is not None else None, \n",
    "                   colors2=nodeColor2DF[step] if nodeColor2DF is not None else None, \n",
    "                   cmap2=ENTROPY_CMAP2, vmin2=colorMin, vmax2=colorMax, alpha2=1.0, \n",
    "                   sizes3=nodeRadii3DF[step] if nodeRadii3DF is not None else None, \n",
    "                   colors3=nodeColor3DF[step] if nodeColor3DF is not None else None, \n",
    "                   cmap3=ENTROPY_CMAP2, vmin3=colorMin, vmax3=colorMax, alpha3=1.0, \n",
    "                   with_labels=(i+1==len(steps)), \n",
    "                   node_labels=nodeLabelsD, font_color=FONT_COLOR\n",
    "                )\n",
    "    \n",
    "    ax.autoscale()\n",
    "    if outfile: \n",
    "        plt.savefig(outfile, bbox_inches='tight')\n",
    "    plt.show()\n",
    "    plt.close(fig)\n",
    "    \n",
    "    return"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Execute the function for the given data set..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "render_entropy_graph(eDF, outfile='test.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "render_entropy_graph(eDF, cDF=eDF2, outfile='test.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "dLL = (get_2v_MIs_for_DF(eDFssa)-get_2v_MIs_for_DF(eDFssa, eDFm)).values.tolist()\n",
    "dL = [v for v in itertools.chain.from_iterable(dLL) if not pd.isna(v)]\n",
    "print(stats.skewtest(dL)) \n",
    "print(stats.kurtosistest(dL))\n",
    "plt.hist(dL, bins=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "dL = list(get_3v_MIs_for_DF(eDFssa)-get_3v_MIs_for_DF(eDFssa, cDF=eDFm))\n",
    "print(stats.skewtest(dL)) \n",
    "print(stats.kurtosistest(dL))\n",
    "plt.hist(dL, bins=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "dLL = (get_2v_MIs_for_DF(eDFssa)-get_2v_MIs_for_DF(eDFm)).values.tolist()\n",
    "dL = [v for v in itertools.chain.from_iterable(dLL) if not pd.isna(v)]\n",
    "print(stats.skewtest(dL)) \n",
    "print(stats.kurtosistest(dL))\n",
    "plt.hist(dL, bins=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "dL = list(get_3v_MIs_for_DF(eDFssa)-get_3v_MIs_for_DF(eDFm))\n",
    "print(stats.skewtest(dL)) \n",
    "print(stats.kurtosistest(dL))\n",
    "plt.hist(dL, bins=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Test visualization for drilling down into target field"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "TARGET_FIELD = 'fog'\n",
    "render_entropy_graph(eDFssa, target_field=TARGET_FIELD, outfile='test2.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "TARGET_FIELD = 'fog'\n",
    "render_entropy_graph(eDFssa, target_field=TARGET_FIELD, cDF=eDFm, outfile='test2.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "dLL = (get_3v_MIs_for_DF_and_target_field(eDFssa, TARGET_FIELD) \\\n",
    "       - get_3v_MIs_for_DF_and_target_field(eDFssa, TARGET_FIELD, cDF=eDFm)).values.tolist()\n",
    "dL = [v for v in itertools.chain.from_iterable(dLL) if not math.isnan(v)]\n",
    "print(stats.skewtest(dL)) \n",
    "print(stats.kurtosistest(dL))\n",
    "plt.hist(dL, bins=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "dL = list(get_4v_MIs_for_DF_and_target_field(eDFssa, target_field=TARGET_FIELD) \\\n",
    "          - get_4v_MIs_for_DF_and_target_field(eDFssa, target_field=TARGET_FIELD, cDF=eDFm))\n",
    "print(stats.skewtest(dL)) \n",
    "print(stats.kurtosistest(dL))\n",
    "plt.hist(dL, bins=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## OLD CODE..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "        legendValue = te = get_E_for_SS(DF[target_field])\n",
    "        scale = get_scale(te, RADIUS_FOR_TOTAL_MUTUAL_INFORMATION)\n",
    "        title, label = GRAPH_TITLE_2 % (target_field), GRAPH_DATASET_LABEL_2 % (target_field, te)\n",
    "        singletonsSS = get_2v_MIs_for_DF_and_target_field(DF, target_field)\n",
    "        scmiDF = get_stepped_cMI_data_for_DF_and_target_field(DF, target_field)\n",
    "        imiDF, cmiDF = scmiDF.applymap(lambda T: T[1]), scmiDF.applymap(lambda T: T[2])\n",
    "        steppedSingletonsDF, steppedSingletonsDF_color = cmiDF, -imiDF\n",
    "        pairsDF = -get_3v_MIs_for_DF_and_target_field(DF, target_field)\n",
    "        tripletsSS = -get_4v_MIs_for_DF_and_target_field(DF, target_field)\n",
    "        \n",
    "        if cDF is not None:\n",
    "            legendValue2 = te2 = get_E_for_SS(DF[target_field],cSS=cDF[target_field])\n",
    "            scale = get_scale(max([te, te2]), RADIUS_FOR_TOTAL_MUTUAL_INFORMATION)\n",
    "            singletons2SS = get_2v_MIs_for_DF_and_target_field(DF, target_field, cDF=cDF)\n",
    "            scmi2DF = get_stepped_cMI_data_for_DF_and_target_field(DF, target_field, cDF=cDF)\n",
    "            imi2DF, cmi2DF = scmi2DF.applymap(lambda T: T[1]), scmi2DF.applymap(lambda T: T[2])\n",
    "            steppedSingletons2DF, steppedSingletons2DF_color = cmi2DF, -imi2DF\n",
    "            pairs2DF = -get_3v_MIs_for_DF_and_target_field(DF, target_field, cDF=cDF)\n",
    "            triplets2SS = -get_4v_MIs_for_DF_and_target_field(DF, target_field, cDF=cDF)\n",
    "            \n",
    "        ewDF = get_3v_2WC_info_for_DF_and_target_field(DF, target_field)\n",
    "        ewDF1 = (ewDF-(ewDF.min().min())).fillna(0)\n",
    "        G1 = nx.from_numpy_matrix(np.matrix(ewDF1))\n",
    "        np1 = nx.spring_layout(G1, iterations=10000)\n",
    "        ewDF2 = (np.absolute(ewDF.fillna(0))**(2))*np.sign(ewDF.fillna(0))\n",
    "        Graph = nx.from_numpy_matrix(np.matrix(ewDF2))\n",
    "        nodePositions = nx.spring_layout(Graph, iterations=10000, pos=np1)\n",
    "\n",
    "        \n",
    "# def test(tDF, cDF):\n",
    "#     tDFrs, cDFrs = _synthesize_by_field_DF(tDF), _synthesize_by_field_DF(cDF)\n",
    "#     tDFjs, cDFjs = _join_split_DFs(tDF, cDF)    \n",
    "\n",
    "#     miSStrs, miSScrs, miSSxrs, miSStjs, miSScjs, miSSxjs = None, None, None, None, None, None\n",
    "#     if True:\n",
    "#         miDFt, miDFc = get_2v_MIs_for_DF(tDF), get_2v_MIs_for_DF(cDF)\n",
    "#         miDFx = get_2v_MIs_for_DF(tDF, cDF)\n",
    "#         miDFtrs, miDFcrs = get_2v_MIs_for_DF(tDFrs), get_2v_MIs_for_DF(cDFrs)\n",
    "#         miDFxrs = get_2v_MIs_for_DF(tDFrs, cDFrs)\n",
    "#         miDFtjs, miDFcjs = get_2v_MIs_for_DF(tDFjs), get_2v_MIs_for_DF(cDFjs)\n",
    "#         miDFxjs = get_2v_MIs_for_DF(tDFjs, cDFjs)\n",
    "#         icL = [(i, c) for c in miDFt for i in miDFt.index if not pd.isna(miDFt[c][i])]\n",
    "#         miSSt = pd.Series([v for c in miDFt for v in miDFt[c] if not pd.isna(v)], index=icL)\n",
    "#         miSSc = pd.Series([v for c in miDFc for v in miDFc[c] if not pd.isna(v)], index=icL)\n",
    "#         miSSx = pd.Series([v for c in miDFx for v in miDFx[c] if not pd.isna(v)], index=icL)\n",
    "#         miSStrs = pd.Series([v for c in miDFtrs for v in miDFtrs[c] if not pd.isna(v)], index=icL)\n",
    "#         miSScrs = pd.Series([v for c in miDFcrs for v in miDFcrs[c] if not pd.isna(v)], index=icL)\n",
    "#         miSSxrs = pd.Series([v for c in miDFxrs for v in miDFxrs[c] if not pd.isna(v)], index=icL)\n",
    "#         miSStjs = pd.Series([v for c in miDFtjs for v in miDFtjs[c] if not pd.isna(v)], index=icL)\n",
    "#         miSScjs = pd.Series([v for c in miDFcjs for v in miDFcjs[c] if not pd.isna(v)], index=icL)\n",
    "#         miSSxjs = pd.Series([v for c in miDFxjs for v in miDFxjs[c] if not pd.isna(v)], index=icL)\n",
    "#     else:\n",
    "#         miSSt, miSSc = get_3v_MIs_for_DF(tDF), get_3v_MIs_for_DF(cDF)\n",
    "#         miSSx = get_3v_MIs_for_DF(tDF, cDF)\n",
    "#         miSStrs, miSScrs = get_3v_MIs_for_DF(tDFrs), get_3v_MIs_for_DF(cDFrs)\n",
    "#         miSSxrs = get_3v_MIs_for_DF(tDFrs, cDFrs)\n",
    "#         miSStjs, miSScjs = get_3v_MIs_for_DF(tDFjs), get_3v_MIs_for_DF(cDFjs)\n",
    "#         miSSxjs = get_3v_MIs_for_DF(tDFjs, cDFjs)\n",
    "        \n",
    "        \n",
    "#     with plt.rc_context({'xtick.color': 'white', 'ytick.color': 'white', 'text.color': 'white'}):\n",
    "#         plt.figure(1, figsize=(12, 18))\n",
    "\n",
    "        \n",
    "#         plt.subplot(3, 2, 1)\n",
    "#         plt.title('Non-normalized Test vs Control')        \n",
    "#         plt.plot(miSStjs, 0.0+1.0*miSStjs, '-', color='green', alpha=0.5)\n",
    "#         plt.scatter(miSSt, miSSc, marker='.', alpha=0.5, \n",
    "#                     c=pd.Series(range(miSSt.size))/miSSt.size, cmap=plt.get_cmap('tab20'))\n",
    "#         plt.scatter(miSStjs, miSScjs, marker='.', alpha=0.1, color='gray')\n",
    "#         plt.scatter(miSStrs, miSScrs, marker='.', alpha=1.0, color='black')\n",
    "\n",
    "        \n",
    "#         plt.subplot(3, 2, 2)\n",
    "#         plt.title('Non-normalized Test vs Cross')\n",
    "#         plt.plot(miSStjs, 0.0+1.0*miSStjs, '-', color='green', alpha=0.5)\n",
    "#         plt.scatter(miSSt, miSSx, marker='.', alpha=0.5, \n",
    "#                     c=pd.Series(range(miSSt.size))/miSSt.size, cmap=plt.get_cmap('tab20'))\n",
    "#         plt.scatter(miSStjs, miSSxjs, marker='.', alpha=0.1, color='gray')\n",
    "#         plt.scatter(miSStrs, miSSxrs, marker='.', alpha=1.0, color='black')\n",
    "\n",
    "        \n",
    "#         plt.subplot(3, 2, 3)\n",
    "#         plt.title('Non-normalized Test vs Control (filtered)')\n",
    "                        \n",
    "#         b1rs, m1rs, fL1rs, oL1rs = get_filtered_linear_least_squares_fit(miSStrs, miSScrs)\n",
    "#         b1js, m1js, fL1js, oL1js = get_filtered_linear_least_squares_fit(miSStjs, miSScjs)\n",
    "\n",
    "#         plt.plot(miSStjs, b1rs+m1rs*miSStjs, '-', color='blue', alpha=0.5)\n",
    "#         plt.plot(miSStjs, b1js+m1js*miSStjs, '-', color='red', alpha=0.5)\n",
    "\n",
    "#         plt.scatter(miSSt, miSSc, marker='.', alpha=0.5, \n",
    "#                     c=pd.Series(range(miSSt.size))/miSSt.size, cmap=plt.get_cmap('tab20'))\n",
    "\n",
    "#         plt.scatter(miSStrs[fL1rs], miSScrs[fL1rs], marker='+', alpha=1.0, color='black')\n",
    "#         plt.scatter(miSStrs[oL1rs], miSScrs[oL1rs], marker='+', alpha=1.0, color='blue')\n",
    "\n",
    "#         plt.scatter(miSStjs[fL1js], miSScjs[fL1js], marker='.', alpha=1.0, color='black')\n",
    "#         plt.scatter(miSStjs[oL1js], miSScjs[oL1js], marker='.', alpha=1.0, color='red')\n",
    "        \n",
    "        \n",
    "#         plt.subplot(3, 2, 4)\n",
    "#         plt.title('Non-normalized Test vs Cross (filtered)')        \n",
    "\n",
    "#         b2rs, m2rs, fL2rs, oL2rs = get_filtered_linear_least_squares_fit(miSStrs, miSSxrs)\n",
    "#         b2js, m2js, fL2js, oL2js = get_filtered_linear_least_squares_fit(miSStjs, miSSxjs)\n",
    "\n",
    "#         plt.plot(miSStjs, b2rs+m2rs*miSStjs, '-', color='blue', alpha=0.5)\n",
    "#         plt.plot(miSStjs, b2js+m2js*miSStjs, '-', color='red', alpha=0.5)\n",
    "\n",
    "#         plt.scatter(miSSt, miSSx, marker='.', alpha=0.5,\n",
    "#                     c=pd.Series(range(miSSt.size))/miSSt.size, cmap=plt.get_cmap('tab20'))\n",
    "\n",
    "#         plt.scatter(miSStrs[fL2rs], miSSxrs[fL2rs], marker='+', alpha=1.0, color='black')\n",
    "#         plt.scatter(miSStrs[oL2rs], miSSxrs[oL2rs], marker='+', alpha=1.0, color='blue')\n",
    "        \n",
    "#         plt.scatter(miSStjs[fL2js], miSSxjs[fL2js], marker='.', alpha=1.0, color='black')\n",
    "#         plt.scatter(miSStjs[oL2js], miSSxjs[oL2js], marker='.', alpha=1.0, color='red')\n",
    "        \n",
    "#     return dSS1\n",
    "# dSS = test(eDF, eDFc)\n",
    "# #print(dSS)\n",
    "        \n",
    "# def shuffle_DF(DF):\n",
    "#     D = {}\n",
    "#     for c, L in [(c, list(DF[c])) for c in DF.columns]:\n",
    "#         random.shuffle(L)\n",
    "#         D[c] = L\n",
    "#     return pd.DataFrame(D, DF.index)\n",
    "\n",
    "# def join_split_DF(DF1, DF2):\n",
    "#     c1, c2, DF1m, DF2m = DF1.shape[0], DF2.shape[0], DF1, DF2\n",
    "#     if c1 < c2:\n",
    "#         m, b = c2 // c1, c2 % c1\n",
    "#         DF1m = pd.concat([DF1]*m + [DF1.iloc[range(b)]])  \n",
    "#     elif c2 < c1:\n",
    "#         m, b = c1 // c2, c1 % c2\n",
    "#         DF2m = pd.concat([DF2]*m + [DF2.iloc[range(b)]])\n",
    "#     jDF = pd.concat(DF1m, DF2m)    \n",
    "#     rSS = pd.Series([random.choice([True, False]) for i in range(jDF.shape[0])], index=jDF.index)\n",
    "#     jsDF1, jsDF2 = jDF.loc[rSS], jDF.loc[~rSS]\n",
    "#     jsDF1.index, jsDF2.index = range(jsDF1.shape[0]), range(jsDF2.shape[0])\n",
    "#     return jsDF1, jsDF2\n",
    "\n",
    "# def get_outlier_filtered_mean_and_stdev(SS, hnorm=False):\n",
    "#     if hnorm: SS = pd.Series(list(np.abs(SS)) + list(-np.abs(SS)))\n",
    "#     q1, q2, q3 = SS.quantile([.25, .5, .75])\n",
    "#     SS2 = SS[(q2-(q3-q1)*1.5 <= SS) & (SS < q2+(q3-q1)*1.5)]\n",
    "#     return np.mean(SS2), np.std(SS2)\n",
    "\n",
    "# def find_P_of_nontrivial_MI(miOt, miOc, miOx, miOtr, miOcr, miOxr):\n",
    "    \n",
    "#     icL, miSSt, miSSc, miSSx = None, miOt, miOc, miOx \n",
    "#     miSStr, miSScr, miSSxr = miOtr, miOcr, miOxr \n",
    "#     if type(miOt) is pd.DataFrame:\n",
    "#         icL = [(i, c) for c in miOt for i in miOt.index if not pd.isna(miOt[c][i])]\n",
    "#         miSSt = pd.Series([v for c in miOt for v in miOt[c] if not pd.isna(v)], index=icL)\n",
    "#         miSSc = pd.Series([v for c in miOc for v in miOc[c] if not pd.isna(v)], index=icL)\n",
    "#         miSSx = pd.Series([v for c in miOx for v in miOx[c] if not pd.isna(v)], index=icL)\n",
    "#         miSStr = pd.Series([v for c in miOtr for v in miOtr[c] if not pd.isna(v)], index=icL)\n",
    "#         miSScr = pd.Series([v for c in miOcr for v in miOcr[c] if not pd.isna(v)], index=icL)\n",
    "#         miSSxr = pd.Series([v for c in miOxr for v in miOxr[c] if not pd.isna(v)], index=icL)\n",
    "                    \n",
    "#     mn_tr, std_tr = get_outlier_filtered_mean_and_stdev(miSStr)\n",
    "#     mn_cr, std_cr = get_outlier_filtered_mean_and_stdev(miSScr)\n",
    "#     dSStr, dSScr = miSStr-mn_tr, miSScr-mn_cr\n",
    "#     miSStcr = np.sqrt(dSStr**2 + dSScr**2)\n",
    "#     mn_tcr, std_tcr = get_outlier_filtered_mean_and_stdev(miSStcr, hnorm=True) \n",
    "#     dSSt, dSSc = miSSt-mn_tr, miSSc-mn_cr\n",
    "#     miSStc = np.sqrt(dSSt**2 + dSSc**2)\n",
    "#     tSStc = np.abs(miSStc-mn_tcr)/std_tcr\n",
    "    \n",
    "#     mn_xr, std_xr = get_outlier_filtered_mean_and_stdev(miSSxr)\n",
    "#     tSSx = np.abs(miSSx-mn_xr)/std_tcr\n",
    "    \n",
    "    \n",
    "#     tSS = pd.Series([min([tSStc[i], tSSx[i]]) for i in tSStc.index], index=tSStc.index)\n",
    "#     tSS2 = pd.Series([max([tSStc[i], tSSx[i]]) for i in tSStc.index], index=tSStc.index)\n",
    "    \n",
    "#     print(len(tSStc[tSStc<3]), len(tSSx[tSSx<3]), len(tSS[tSS<3]), len(tSS2[tSS2<3]))\n",
    "    \n",
    "#     #print(pd.DataFrame({'tSStc': tSStc, 'tSSx': tSSx, #'tSS': tSS\n",
    "#     #                   }, index=tSStc.index))\n",
    " \n",
    "#     pO = pd.Series(1.0-stats.t.sf(tSS, len(tSS)-1), index=tSS.index)\n",
    "#     if type(miOt) is pd.DataFrame:\n",
    "#         pD = {c: [np.NaN]*miOt.shape[1] for c in miOt.columns}\n",
    "#         for i, c in icL: pD[c][miOt.index.get_loc(i)] = pO[(i, c)]\n",
    "#         pO = pd.DataFrame(pD, miOt.index)\n",
    "#     return pO        \n",
    "\n",
    "# def find_P_of_nontrivial_MI_diff(miOt, miOc, miOx, miOtr, miOcr, miOxr, \n",
    "#                                  miOtjs, miOcjs, miOxjs, pO): \n",
    "    \n",
    "#     icL, miSSt, miSSc, miSSx = None, miOt, miOc, miOx\n",
    "#     miSStr, miSScr, miSSxr = miOtr, miOcr, miOxr\n",
    "#     miSStjs, miSScjs, miSSxjs, pSS = miOtjs, miOcjs, miOxjs, pO \n",
    "#     if type(miOt) is pd.DataFrame:\n",
    "#         icL = [(i, c) for c in miOt for i in miOt.index if not pd.isna(miOt[c][i])]\n",
    "#         miSSt = pd.Series([v for c in miOt for v in miOt[c] if not pd.isna(v)], index=icL)\n",
    "#         miSSc = pd.Series([v for c in miOc for v in miOc[c] if not pd.isna(v)], index=icL)\n",
    "#         miSSx = pd.Series([v for c in miOx for v in miOx[c] if not pd.isna(v)], index=icL)\n",
    "\n",
    "#         miSStr = pd.Series([v for c in miOtr for v in miOtr[c] if not pd.isna(v)], index=icL)\n",
    "#         miSScr = pd.Series([v for c in miOcr for v in miOcr[c] if not pd.isna(v)], index=icL)\n",
    "#         miSSxr = pd.Series([v for c in miOxr for v in miOxr[c] if not pd.isna(v)], index=icL)\n",
    "\n",
    "#         miSStjs = pd.Series([v for c in miOtjs for v in miOtjs[c] if not pd.isna(v)], index=icL)\n",
    "#         miSScjs = pd.Series([v for c in miOcjs for v in miOcjs[c] if not pd.isna(v)], index=icL)\n",
    "#         miSSxjs = pd.Series([v for c in miOxjs for v in miOxjs[c] if not pd.isna(v)], index=icL)\n",
    "#         pSS = pd.Series([v for c in pO for v in pO[c] if not pd.isna(v)], index=icL)\n",
    "            \n",
    "#     dSStc = (miSStjs-miSScjs)[pSS>0.997]\n",
    "#     mn_tc, std_tc = get_outlier_filtered_mean_and_stdev(dSStc, hnorm=True)\n",
    "#     tSStc = np.abs((miSSt-miSSc)/std_tc)\n",
    "    \n",
    "#     dSSx = (miSStjs-miSSxjs)[pSS>0.997]\n",
    "#     mn_x, std_x = get_outlier_filtered_mean_and_stdev(dSSx)\n",
    "#     tSSx = np.abs(((miSSt-miSSx)-mn_x)/std_x)\n",
    "\n",
    "#     tSS = pd.Series([min([tSStc[i], tSSx[i]]) for i in tSStc.index], index=tSStc.index)\n",
    "    \n",
    "#     print('all')\n",
    "#     print(pd.DataFrame({'tSStc': tSStc[pSS>0.997], \n",
    "#                         'tSSx': tSSx[pSS>0.997], \n",
    "#                        },\n",
    "#                        index=tSStc[pSS>0.997].index))\n",
    "#     print()\n",
    "#     print('tc:')\n",
    "#     print(pd.DataFrame({'tSStc': tSStc[(pSS>=0.997) & (tSStc>=3)], \n",
    "#                         'tSSx': tSSx[(pSS>=0.997) & (tSStc>=3)],\n",
    "#                        },\n",
    "#                        index=tSStc[(pSS>=0.997) & (tSStc>=3)].index))\n",
    "#     print()\n",
    "#     print('x:')\n",
    "#     print(pd.DataFrame({'tSStc': tSStc[(pSS>=0.997) & (tSSx>=3)], \n",
    "#                         'tSSx': tSSx[(pSS>=0.997) & (tSSx>=3)], \n",
    "#                        },\n",
    "#                        index=tSSx[(pSS>=0.997) & (tSSx>=3)].index))\n",
    "    \n",
    "#     pO = pd.Series(1.0-stats.t.sf(tSS, len(tSS)-1), index=tSS.index)\n",
    "#     if type(miOt) is pd.DataFrame:\n",
    "#         pD = {c: [np.NaN]*miOt.shape[1] for c in miOt.columns}\n",
    "#         for i, c in icL: pD[c][miOt.index.get_loc(i)] = pO[(i, c)]\n",
    "#         pO = pd.DataFrame(pD, miOt.index)\n",
    "#     return pO\n",
    "        \n",
    "# def get_bkg_colormap():\n",
    "#     cMap = cc.cm['bkr']\n",
    "#     sdD, sdD2 = cMap.__dict__['_segmentdata'], {}\n",
    "#     r1, r2 = sdD['red'][:128], sdD['red'][128:]\n",
    "#     b1, b2 = sdD['blue'][:128], sdD['blue'][128:]\n",
    "#     g1, g2 = sdD['green'][:128], sdD['green'][128:]    \n",
    "#     sdD2['red'] = r1 + [(r2[i][0], *r1[127-i][1:]) for i in range(128)]\n",
    "#     sdD2['blue'] = b1 + [(b2[i][0], *g1[127-i][1:]) for i in range(128)]\n",
    "#     sdD2['green'] = g1 + [(g2[i][0], *b1[127-i][1:]) for i in range(128)]\n",
    "#     return cc.LinearSegmentedColormap('bkg',  sdD2)\n",
    "\n",
    "# def get_yky_colormap():\n",
    "#     cMap, e = cc.cm['bkr'], 4\n",
    "#     sdD, sdD2 = cMap.__dict__['_segmentdata'], {}    \n",
    "#     r1, r2 = sdD['red'][:128], sdD['red'][128:]\n",
    "#     g1, g2 = sdD['green'][:128], sdD['green'][128:]        \n",
    "#     b1, b2 = sdD['blue'][:128], sdD['blue'][128:]    \n",
    "#     sdD2['red'] = [(r1[i][0], r2[127-i][1]**e, r2[127-i][2]**e) for i in range(128)] \\\n",
    "#             + [(r2[i][0], r2[i][1]**e, r2[i][2]**e) for i in range(128)]\n",
    "#     sdD2['green'] = [(r1[i][0], r2[127-i][1]**e, r2[127-i][2]**e) for i in range(128)] \\\n",
    "#             + [(r2[i][0], r2[i][1]**e, r2[i][2]**e) for i in range(128)]\n",
    "#     sdD2['blue'] = [(b1[i][0], b2[127-i][1]**e, b2[127-i][2]**e) for i in range(128)] \\\n",
    "#             + [(b2[i][0], b2[i][1]**e, b2[i][2]**e) for i in range(128)]\n",
    "#     return cc.LinearSegmentedColormap('yky',  sdD2)\n",
    "\n",
    "# def _get_0norm_filtered_SS(SS):\n",
    "#     sSS = SS.sort_values()\n",
    "#     min_zNiL, max_dNiL, last_vz = [], [], None\n",
    "#     for i in range(10, sSS.size):\n",
    "#         mSS = pd.concat([sSS[:i], -sSS[:i]])\n",
    "#         z, p = stats.kurtosistest(mSS)\n",
    "#         std, v, z = np.std(mSS), sSS[i], abs(z)\n",
    "#         vz = v/std\n",
    "        \n",
    "#         s = '%d. %.6f (p=%.6f)  ->  v=%.6f, std=%.6f : %.6f' % (i, z, p, v, std, vz)\n",
    "\n",
    "#         if z and ((not min_zNiL) or z<=min_zNiL[-1][0]):\n",
    "#             min_zNiL.append((z, i))\n",
    "#             s += ' !'  \n",
    "\n",
    "#         if last_vz and ((not max_dNiL) or vz-last_vz>=max_dNiL[-1][0]):\n",
    "#             max_dNiL.append((vz-last_vz, i))\n",
    "#             s += ' *'\n",
    "            \n",
    "#         if z == 0: s += ' X'\n",
    "#         print(s)\n",
    "        \n",
    "#         last_vz = vz\n",
    "        \n",
    "#     min_zi = min_zNiL[-1][1]+1\n",
    "#     i = ([min_zi]+[dNi[1] for dNi in max_dNiL if dNi[1] <= min_zi])[-1] \n",
    "#     print(min_zi, i)\n",
    "#     return sSS[:i]\n",
    "\n",
    "#def test(tDF, cDF):\n",
    "#    tDFr, cDFr = _synthesize_by_field_DF(tDF), _synthesize_by_field_DF(cDF)\n",
    "#    miSStr, miSScr = get_3v_MIs_for_DF(tDFr), get_3v_MIs_for_DF(cDFr)\n",
    "#    dSS_mi0n = _get_0norm_filtered_SS(np.sqrt(miSStr**2+miSScr**2))\n",
    "#    return dSS_mi0n\n",
    "#test(eDF, eDFc)\n",
    "    \n",
    "#     tDFr2, cDFr2 = _synthesize_by_field_DF(tDF), _synthesize_by_field_DF(cDF)\n",
    "#     miSStr2, miSScr2 = get_3v_MIs_for_DF(tDFr2), get_3v_MIs_for_DF(cDFr2) \n",
    "#     miSSxr2 = get_3v_MIs_for_DF(tDFr2, cDFr2) \n",
    "#     if True:\n",
    "#         plt.figure(1, figsize=(12, 12))\n",
    "#         plt.subplot(2, 2, 1)\n",
    "#         plt.scatter(miSStr, miSStr2, marker='.',\n",
    "#                     c=pd.Series(range(miSStr.size))/miSStr.size, cmap=plt.get_cmap('tab20'))\n",
    "#         plt.subplot(2, 2, 2)\n",
    "#         plt.scatter(miSScr, miSScr2, marker='.',\n",
    "#                     c=pd.Series(range(miSScr.size))/miSScr.size, cmap=plt.get_cmap('tab20'))\n",
    "#         plt.figure(1, figsize=(12, 12))\n",
    "#         plt.subplot(2, 2, 3)\n",
    "#         plt.scatter(miSSxr, miSSxr2, marker='.',\n",
    "#                     c=pd.Series(range(miSSxr.size))/miSSxr.size, cmap=plt.get_cmap('tab20'))\n",
    "\n",
    "#     if False:\n",
    "#         plt.figure(1, figsize=(12, 24))\n",
    "#         plt.subplot(4, 2, 1)\n",
    "#         plt.scatter(tSStc_eq, tSSx_eq, marker='.', color='white')\n",
    "#         plt.scatter(tSStc_no, tSSx_no, marker='.', color='green')\n",
    "#         #plt.axis('equal')\n",
    "\n",
    "#         plt.subplot(4, 2, 3)\n",
    "#         plt.scatter(miSStr, miSScr, marker='.', color='yellow')\n",
    "\n",
    "#         plt.scatter([miSStr.mean()], [miSScr.mean()], color='pink')\n",
    "        \n",
    "#         mn_js1, std_js1 = _get_outlier_filtered_mean_and_stdev(miSSjs1)\n",
    "#         mn_js2, std_js2 = _get_outlier_filtered_mean_and_stdev(miSSjs2)\n",
    "#         b, m = 0, mn_js2/mn_js1\n",
    "#         #b, m = polyfit(miSSjs1, miSSjs2, 1)\n",
    "#         plt.plot(miSSjs1, b+m*miSSjs1, '-', color='orange', alpha=0.5)\n",
    "\n",
    "#         plt.scatter(miSSjs1, miSSjs2, marker='.', color='orange')\n",
    "#         plt.axis('equal')\n",
    "\n",
    "#         plt.subplot(4, 2, 5)\n",
    "#         #plt.scatter(miSStr, miSScr, marker='.', color='yellow', alpha=0.25)\n",
    "\n",
    "#         plt.scatter([miSStr.mean()], [miSScr.mean()], color='pink')\n",
    "#         mn_js1, std_js1 = _get_outlier_filtered_mean_and_stdev(miSSjs1)\n",
    "#         mn_js2, std_js2 = _get_outlier_filtered_mean_and_stdev(miSSjs2)\n",
    "#         b, m = 0, mn_js2/mn_js1\n",
    "#         #b, m = polyfit(miSSjs1, miSSjs2, 1)\n",
    "#         plt.plot(miSSjs1, b+m*miSSjs1, '-', color='orange', alpha=0.5)\n",
    "#         plt.scatter(miSSjs1, miSSjs2, marker='.', color='orange', alpha=0.25)\n",
    "        \n",
    "#         mn_t, std_t = _get_outlier_filtered_mean_and_stdev(miSSt)\n",
    "#         mn_c, std_c = _get_outlier_filtered_mean_and_stdev(miSSc)\n",
    "#         b2, m2 = 0, mn_c/mn_t\n",
    "#         #b2, m2 = polyfit(miSSt, miSSc, 1)\n",
    "#         plt.plot(miSSjs1, b2+m2*miSSjs1, '-', color='red', alpha=0.5)\n",
    "#         plt.scatter(miSSt, miSSc, marker='.', color='red')\n",
    "#         plt.scatter(miSSt[fSS_eq], miSSc[fSS_eq], marker='.', color='gray')\n",
    "#         #plt.scatter(miSSt[fSS_no], miSSc[fSS_no], marker='.', color='black')\n",
    "#         plt.axis('equal')\n",
    "\n",
    "#         plt.subplot(4, 2, 7)\n",
    "#         #plt.scatter(miSStr, miSScr, marker='.', color='yellow', alpha=0.25)\n",
    "#         plt.scatter(miSSjs1, miSSjs2, marker='.', color='orange', alpha=0.25)\n",
    "#         plt.scatter(miSSt, miSSc, marker='.', color='red')\n",
    "#         plt.scatter(miSSt[fSS_eq2], miSSc[fSS_eq2], marker='.', color='gray')\n",
    "#         #plt.scatter(miSSt[fSS_no2], miSSc[fSS_no2], marker='.', color='black')\n",
    "#         plt.axis('equal')\n",
    "        \n",
    "#         plt.subplot(4, 2, 2)\n",
    "#         plt.scatter(tSStc_no, tSSx_no, marker='.', color='white')\n",
    "#         plt.scatter(tSStc_eq, tSSx_eq, marker='.', color='green')\n",
    "#         #plt.axis('equal')\n",
    "\n",
    "#         plt.subplot(4, 2, 4)\n",
    "#         plt.scatter(miSStr, miSSxr, marker='.', color='yellow')\n",
    "#         plt.scatter([miSStr.mean()], [miSSxr.mean()], color='pink')\n",
    "        \n",
    "#         mn_js1, std_js1 = _get_outlier_filtered_mean_and_stdev(miSSjs1)\n",
    "#         mn_jsX, std_jsX = _get_outlier_filtered_mean_and_stdev(miSSjsX)\n",
    "#         b, m = 0, mn_jsX/mn_js1\n",
    "#         #b, m = polyfit(miSSjs1, miSSjsX, 1)\n",
    "#         plt.plot(miSSjs1, b+m*miSSjs1, '-', color='orange', alpha=0.5)\n",
    "#         plt.scatter(miSSjs1, miSSjsX, marker='.', color='orange')\n",
    "#         #plt.axis('equal')\n",
    "\n",
    "#         plt.subplot(4, 2, 6)\n",
    "#         #plt.scatter(miSStr, miSSxr, marker='.', color='yellow', alpha=0.25)\n",
    "#         plt.scatter(miSSjs1, miSSjsX, marker='.', color='orange', alpha=0.25)\n",
    "#         plt.scatter(miSSt, miSSx, marker='.', color='red')\n",
    "#         plt.scatter(miSSt[fSS_eq], miSSx[fSS_eq], marker='.', color='gray')\n",
    "#         #plt.scatter(miSSt[fSS_no], miSSx[fSS_no], marker='.', color='black')\n",
    "#         #plt.axis('equal')\n",
    "\n",
    "#         plt.subplot(4, 2, 8)\n",
    "#         #plt.scatter(miSStr, miSSxr, marker='.', color='yellow', alpha=0.25)\n",
    "#         plt.scatter([miSStr.mean()], [miSSxr.mean()], color='pink')\n",
    "        \n",
    "#         mn_js1, std_js1 = _get_outlier_filtered_mean_and_stdev(miSSjs1)\n",
    "#         mn_jsX, std_jsX = _get_outlier_filtered_mean_and_stdev(miSSjsX)\n",
    "#         b, m = 0, mn_jsX/mn_js1\n",
    "#         #b, m = polyfit(miSSjs1, miSSjsX, 1)    \n",
    "#         plt.plot(miSSjs1, b+m*miSSjs1, '-', color='orange', alpha=0.5)\n",
    "#         plt.scatter(miSSjs1, miSSjsX, marker='.', color='orange', alpha=0.25)\n",
    "\n",
    "#         mn_t, std_t = _get_outlier_filtered_mean_and_stdev(miSSt)\n",
    "#         mn_x, std_x = _get_outlier_filtered_mean_and_stdev(miSSx)\n",
    "#         b2, m2 = 0, mn_x/mn_t\n",
    "#         #b2, m2 = polyfit(miSSt, miSSx, 1)\n",
    "#         plt.plot(miSSjs1, b2+m2*miSSjs1, '-', color='red', alpha=0.5)\n",
    "#         plt.scatter(miSSt, miSSx, marker='.', color='red')\n",
    "#         plt.scatter(miSSt[fSS_eq2], miSSx[fSS_eq2], marker='.', color='gray')\n",
    "#         #plt.scatter(miSSt[fSS_no2], miSSx[fSS_no2], marker='.', color='black')\n",
    "#         #plt.axis('equal')\n",
    "    \n",
    "#     plt.figure(1, figsize=(10, 20))\n",
    "#     plt.subplot(2,1,1)\n",
    "#     miSSd = (miSSt-miSSc)#/np.sqrt(miSSt**2+miSSc**2)\n",
    "#     plt.scatter(miSSt, miSSd, marker='.', color='orange')\n",
    "#     plt.scatter(miSSt[(pSS<0.997)], miSSd[(pSS<0.997)], marker='.', color='black')\n",
    "#     plt.scatter(miSSt[(tSStc*tSSx>=9)], miSSd[(tSStc*tSSx>=9)], marker='+', color='red')\n",
    "\n",
    "#     plt.subplot(2,1,2)\n",
    "#     miSSd2 = miSSx\n",
    "#     plt.scatter(miSSt[(pSS>=0.997)], miSSd2[(pSS>=0.997)], marker='.', color='orange')\n",
    "#     plt.scatter(miSSt[(pSS<0.997)], miSSd2[(pSS<0.997)], marker='.', color='black')\n",
    "#     plt.scatter(miSSt[(tSStc*tSSx>=9)], miSSd2[(tSStc*tSSx>=9)], marker='+', color='red')\n",
    "\n",
    "    \n",
    "#     rSS = pd.Series([random.random() for i in range(miSSx.size)], index=miSSx.index)\n",
    "#     plt.scatter((miSSx-miSSxjs), rSS, marker='.', color='orange')\n",
    "#     plt.scatter((miSSx-miSSxjs)[(pSS<0.997)], rSS[(pSS<0.997)], marker='.', color='black')\n",
    "#     plt.scatter((miSSx-miSSxjs)[(tSStc*tSSx>=9)], rSS[(tSStc*tSSx>=9)], marker='+', color='red')\n",
    "    \n",
    "    #plt.scatter(np.abs(miSSt-miSSc), np.abs(miSSx), marker='.', color='orange')\n",
    "    #plt.scatter(np.abs(miSSt-miSSc)[(pSS<0.997)], np.abs(miSSx)[(pSS<0.997)], \n",
    "    #            marker='.', color='black')\n",
    "    #plt.scatter(np.abs(miSSt-miSSc)[(tSStc*tSSx>=9)], np.abs(miSSx)[(tSStc*tSSx>=9)], \n",
    "    #            marker='+', color='red')\n",
    "\n",
    "    #plt.figure(1, figsize=(10, 30))\n",
    "    #plt.subplot(3, 1, 1)\n",
    "    #plt.scatter(miSStr, miSScr, marker=\".\", color='deepskyblue', alpha=0.1)\n",
    "    #plt.scatter(miSStjs, miSScjs, marker='.', color='limegreen', alpha=0.3)\n",
    "    #plt.scatter(miSSt, miSSc, marker='.', color='orange', alpha=0.3)\n",
    "\n",
    "    #plt.scatter(miSStjs, miSScjs, marker='.', color='yellow', alpha=0.5)\n",
    "    #plt.scatter(miSSt[tSS<3], miSSc[tSS<3], marker='.', color='deepskyblue', alpha=0.5)\n",
    "    #plt.scatter(miSSt[tSS>=3], miSSc[tSS>=3], marker='.', color='blue', alpha=1)\n",
    "    #plt.scatter(miSSt[(tSSx>=3) & (tSStc<3)], miSSc[(tSSx>=3) & (tSStc<3)], \n",
    "    #            marker='.', color='red', alpha=1)\n",
    "    #plt.scatter(miSSt[(tSStc>=3) & (tSSx<3)], miSSc[(tSStc>=3) & (tSSx<3)], \n",
    "    #            marker='.', color='limegreen', alpha=1)\n",
    "    #plt.scatter(miSSt[(pSS<0.997)], miSSc[(pSS<0.997)], \n",
    "    #            marker='.', color='black', alpha=0.5)\n",
    "    #plt.scatter(miSSt[(tSStc*tSSx>=9)], miSSc[(tSStc*tSSx>=9)], \n",
    "    #            marker='+', color='red', alpha=1)\n",
    "\n",
    "    #plt.subplot(3, 1, 2)\n",
    "    #plt.scatter(miSStr, miSSxr, marker='.', color='deepskyblue', alpha=0.3)\n",
    "    #plt.scatter(miSStjs, miSSxjs, marker='.', color='limegreen', alpha=0.3)\n",
    "    #plt.scatter(miSSt, miSSx, marker='.', color='orange', alpha=0.3)\n",
    "    #plt.scatter(miSStjs, miSSxjs, marker='.', color='yellow', alpha=0.5)\n",
    "    #plt.scatter(miSSt[tSS<3], miSSx[tSS<3], marker='.', color='deepskyblue', alpha=0.5)\n",
    "    #plt.scatter(miSSt[tSS>=3], miSSx[tSS>=3], marker='.', color='blue', alpha=1)\n",
    "    #plt.scatter(miSSt[(tSSx>=3) & (tSStc<3)], miSSx[(tSSx>=3) & (tSStc<3)], \n",
    "    #            marker='.', color='red', alpha=1)\n",
    "    #plt.scatter(miSSt[(tSStc>=3) & (tSSx<3)], miSSx[(tSStc>=3) & (tSSx<3)], \n",
    "    #            marker='.', color='limegreen', alpha=1)\n",
    "    #plt.scatter(miSSt[(pSS<0.997)], miSSx[(pSS<0.997)], \n",
    "    #            marker='.', color='black', alpha=0.5)\n",
    "    #plt.scatter(miSSt[(tSStc*tSSx>=9)], miSSx[(tSStc*tSSx>=9)], \n",
    "    #            marker='+', color='red', alpha=1)\n",
    "\n",
    "    #plt.subplot(3, 1, 3)\n",
    "    #plt.scatter(tSStc[tSS<3], tSSx[tSS<3], marker='.', color='deepskyblue', alpha=0.5)\n",
    "    #plt.scatter(tSStc[tSS>=3], tSSx[tSS>=3], marker='.', color='blue', alpha=1)\n",
    "    #plt.scatter(tSStc[(tSSx>=3) & (tSStc<3)], tSSx[(tSSx>=3) & (tSStc<3)], \n",
    "    #           marker='.', color='red', alpha=1)\n",
    "    #plt.scatter(tSStc[(tSStc>=3) & (tSSx<3)], tSSx[(tSStc>=3) & (tSSx<3)], \n",
    "    #           marker='.', color='limegreen', alpha=1)\n",
    "    #plt.scatter(tSStc[(tSStc*tSSx>=9)], tSSx[(tSStc*tSSx>=9)], \n",
    "    #           marker='+', color='black', alpha=1)\n",
    "    #plt.scatter(tSStc[(pSS<0.997)], tSSx[(pSS<0.997)], \n",
    "    #           marker='.', color='gray', alpha=0.5)\n",
    "    \n",
    "# def get_E_for_SS(SS, cSS=None, tflag=None):    \n",
    "#     p_counter = collect.Counter(SS)\n",
    "#     if len(p_counter) <= 1:\n",
    "#         raise AssertionError('Target Series must have at least 2 states')\n",
    "#     e = None\n",
    "#     if cSS is None:\n",
    "#         e = stats.entropy(list(p_counter.values()), base=2)\n",
    "#     elif cSS is not None:\n",
    "#         q_counter = collect.Counter(cSS) \n",
    "#         if len(q_counter) <= 1:\n",
    "#             raise AssertionError('Reference Series must have at least 2 states')\n",
    "#         pk, qk = [], []\n",
    "#         for k in pd.Series(sorted(list(set( p_counter.keys()) | set(q_counter.keys()) ))):\n",
    "#             if k in p_counter and k in q_counter:\n",
    "#                 pk.append(p_counter[k])\n",
    "#                 qk.append(q_counter[k])\n",
    "#             elif k not in p_counter and k in q_counter:\n",
    "#                 pk.append(0)\n",
    "#                 qk.append(q_counter[k])\n",
    "#             elif k in p_counter and k not in q_counter:    \n",
    "#                 pk.append(0)\n",
    "#                 qk.append(p_counter[k])\n",
    "#                 #raise AssertionError(\n",
    "#                 #        'Kullback-Leibler requirement: ' + \n",
    "#                 #        'Reference Membership must contain Target Membership'\n",
    "#                 #    )\n",
    "#         e = stats.entropy(pk, base=2) + stats.entropy(pk, qk=qk, base=2)\n",
    "#     return e\n",
    "    \n",
    "# def get_E_for_SS(SS, cSS=None, refEntropy=None, tflag=None):\n",
    "#     p_counter = collect.Counter(SS)\n",
    "#     if len(p_counter) <= 1:\n",
    "#         raise AssertionError('Target Series must have at least 2 states')\n",
    "#     e = None\n",
    "#     if cSS is not None:\n",
    "#         q_counter = collect.Counter(cSS) \n",
    "#         if len(q_counter) <= 1:\n",
    "#             raise AssertionError('Reference Series must have at least 2 states')\n",
    "#         pk, qk = [], []\n",
    "#         for k in pd.Series(sorted(list(set( p_counter.keys()) | set(q_counter.keys()) ))):\n",
    "#             if k in p_counter and k in q_counter:\n",
    "#                 pk.append(p_counter[k])\n",
    "#                 qk.append(q_counter[k])\n",
    "#             elif k not in p_counter and k in q_counter:\n",
    "#                 pk.append(0)\n",
    "#                 qk.append(q_counter[k])\n",
    "#             elif k in p_counter and k not in q_counter:    \n",
    "#                 raise AssertionError(\n",
    "#                         'Kullback-Leibler requirement: ' + \n",
    "#                         'Reference Membership must contain Target Membership'\n",
    "#                     )\n",
    "#         e = stats.entropy(pk, base=2) + stats.entropy(pk, qk=qk, base=2)\n",
    "#         if tflag and tflag == 'alt':\n",
    "#             e = stats.entropy(pk, qk=qk, base=2)\n",
    "#     elif refEntropy is not None:\n",
    "#         e = stats.entropy(list(p_counter.values()), base=2) - refEntropy        \n",
    "#     elif cSS is None and refEntropy is None:\n",
    "#         e = stats.entropy(list(p_counter.values()), base=2)\n",
    "#     return e\n",
    "\n",
    "# b, m = polyfit(miSSt, miSSc, 1)\n",
    "\n",
    "# mdn, iqr = dSS1.median(), abs(dSS1.quantile(0.75)-dSS1.quantile(0.25))\n",
    "# miSSt_iqr = miSSt[(mdn - (iqr*1.5) <= dSS1) & (dSS1 < mdn + (iqr*1.5))]\n",
    "# miSSc_iqr = miSSc[(mdn - (iqr*1.5) <= dSS1) & (dSS1 < mdn + (iqr*1.5))]\n",
    "# b2, m2 = polyfit(miSSt_iqr, miSSc_iqr, 1)\n",
    "\n",
    "# plt.plot(miSSt, miSSt, '-', color='yellow', alpha=0.5)\n",
    "# plt.plot(miSSt, b+m*miSSt, '-', color='orange', alpha=0.5)\n",
    "# plt.plot(miSSt, b2+m2*miSSt, '-', color='red', alpha=0.5)\n",
    "    \n",
    "#print(list(miSSt))\n",
    "#print(min(miSSt), max(miSSt))\n",
    "#print(list(miSSc))\n",
    "#print(min(miSSc), max(miSSc))\n",
    "\n",
    "#b, m = polyfit(miSSt, miSSc, 1)\n",
    "#m2 = miSSt.dot(miSSc)/miSSt.dot(miSSt)\n",
    "#m3 = miSSc.mean()/miSSt.mean()\n",
    "#m4 = miSSc.median()/miSSt.median()\n",
    "#print(m, m2, m3)\n",
    "#plt.plot(miSSt, miSSt, '-')\n",
    "#plt.plot(miSSt, b + m * miSSt, '-')\n",
    "#plt.plot(miSSt, m3*miSSt, '-')\n",
    "#plt.plot(miSSt, m4*miSSt, '-')\n",
    "#plt.scatter(miSSt, miSSc, marker='.', c=catSS1b, alpha=0.5)\n",
    "#plt.plot([miSSt.mean()], [miSSc.mean()], 'o', c='black')\n",
    "#print(b, m)\n",
    "#x = miSSt.mean()\n",
    "#print(x, b+m*x, m3*x)\n",
    "\n",
    "#tDF[tDF['t-c']]\n",
    "    \n",
    "        \n",
    "# LETTER_COLOR_DICT = {\n",
    "#         'A':'coral', 'B': 'gold', 'C': 'springgreen', 'D': 'dodgerblue', \n",
    "#         'E': 'lavender', 'F': 'pink', 'G': 'chocolate', 'H': 'orange', \n",
    "#         'I': 'teal', 'J': 'cadetblue', 'K': 'blueviolet', 'L': 'purple',\n",
    "#         'M': 'rosybrown', 'N': 'goldenrod', 'O': 'lawngreen', 'P': 'aqua', \n",
    "#         'Q': 'slateblue', 'R': 'orchid', 'S': 'palevioletred', 'T': 'peachpuff', \n",
    "#         'U': 'r', 'V': 'y', 'W': 'g', 'X': 'c', 'Y': 'b', 'Z': 'm'\n",
    "#     }\n",
    "        \n",
    "# def entropy2rank(pdO):\n",
    "#     pdO2 = None\n",
    "#     if type(pdO) is pd.Series:\n",
    "#         pdO2 = pd.Series([v for v in stats.rankdata(pdO)], index=pdO.index)\n",
    "#     elif type(pdO) is pd.DataFrame:\n",
    "#         rankL = stats.rankdata([v for c in pdO.columns for v in pdO[c] if not pd.isna(v)])\n",
    "#         D, i = {}, 0\n",
    "#         for c in pdO.columns:\n",
    "#             L = []\n",
    "#             for r in pdO.index:\n",
    "#                 if pd.isna(pdO[c][r]): L.append(None)\n",
    "#                 else: \n",
    "#                     L.append(rankL[i])\n",
    "#                     i += 1\n",
    "#             D[c] = L\n",
    "#         pdO2 = pd.DataFrame(D, columns=pdO.columns, index=pdO.index)\n",
    "#     return pdO2\n",
    "\n",
    "#eOB_ref = get_unique_values_for_DF(eDFm)\n",
    "\n",
    "# legendValue = get_jE_for_DF(eDF_target)\n",
    "# legendValue2 = get_jE_for_DF(eDF_target, eOB_ref)\n",
    "# print(\"E=%f, E_kl=%f\" % (legendValue, legendValue2))\n",
    "# print('---')\n",
    "\n",
    "# pairDFa = get_2v_MIs_for_DF(eDF_target)\n",
    "# pair2DFa = get_2v_MIs_for_DF(eDF_target, cDF=eOB_ref)\n",
    "# print('MI2:')\n",
    "# print(pairDFa.values.tolist())\n",
    "# print('---')\n",
    "# print('MI2_kl:')\n",
    "# print(pair2DFa.values.tolist())\n",
    "# print('---')\n",
    "\n",
    "# tripletsSSa = get_3v_MIs_for_DF(eDF_target)\n",
    "# triplets2SSa = get_3v_MIs_for_DF(eDF_target, cDF=eOB_ref)\n",
    "# print('MI3:')\n",
    "# print(tripletsSSa.tolist())\n",
    "# print('---')\n",
    "# print('MI3_kl:')\n",
    "# print(triplets2SSa.tolist())\n",
    "# print('---')\n",
    "\n",
    "# plt.axvline(0, color='black', linestyle='dashed', alpha=0.5)\n",
    "# plt.hist(tripletsSSa, label='MI3')\n",
    "# plt.hist(triplets2SSa, label='MI3_kl')\n",
    "# plt.legend(facecolor='black')\n",
    "# matplotlib.rcParams.update({'text.color': 'white'})\n",
    "#plt.plot(tripletsSSa, triplets2SSa, 'bo', tripletsSSa, a, 'gs') #, a, triplets2SSa, 'r^')\n",
    "#plt.axis('equal')\n",
    "\n",
    "#render_entropy_graph(eDFm, cDF=eDF2m, outfile='test.png')\n",
    "    \n",
    "    \n",
    "\n",
    "#def get_E_for_SS2(SS, cSS=None, keySS=None, refEntropy=None):\n",
    "#    p_counter = collect.Counter(SS)\n",
    "#    e = None\n",
    "#    if cSS is not None:\n",
    "#        q_counter = collect.Counter(cSS)\n",
    "#        pk, qk = [], []\n",
    "#        if keySS is None: keySS = pd.Series(sorted(list(set( p_counter.keys()) | set(q_counter.keys()) ))) \n",
    "#        for k in keySS:\n",
    "#            pk.append(((p_counter[k] if k in p_counter else 0) + 0.00001))\n",
    "#            qk.append(((q_counter[k] if k in q_counter else 0) + 0.00001))\n",
    "#        e = -stats.entropy(pk, qk=qk, base=2)    \n",
    "#    elif refEntropy is not None:\n",
    "#         e = stats.entropy(list(p_counter.values()), base=2) - refEntropy\n",
    "#     elif cSS is None and refEntropy is None:\n",
    "#         e = stats.entropy(list(p_counter.values()), base=2)\n",
    "#     return e\n",
    "\n",
    "#def get_E_for_SS2(SS, cSS=None):\n",
    "#    pk, qk = list(collect.Counter(SS).values()), list(collect.Counter(cSS).values()) if cSS is not None else None \n",
    "#    return 0.0 if SS.empty else stats.entropy(pk, qk=qk, base=2)\n",
    "\n",
    "#def get_Es_for_DF2(DF, refDF = None):\n",
    "#    return DF.apply(get_E_for_SS)\n",
    "\n",
    "#q_counter = collect.Counter(cSS)\n",
    "#qk = list(q_counter.values())\n",
    "#pk.extend([0]*(len(qk)-len(pk)))\n",
    "#e2 = stats.entropy(qk, base=2)\n",
    "# ----------------\n",
    "#e3 = stats.entropy(pk, qk=qk, base=2)\n",
    "#if round(e3, 10) != round(abs(e1-e2), 10): \n",
    "#    print(round(e3, 10), '==?', round(abs(e1-e2), 10), (e1, '-',  e2, '=', e1-e2))\n",
    "#    raise AssertionError('Kullback-Leibler != difference in entropy between series')\n",
    "# ----------------\n",
    "\n",
    "#if cDF is not None:\n",
    "#    pairs2DFm = pairs2DF.fillna(0.0) + pairs2DF.T.fillna(0.0)\n",
    "#    steppedSingletonsDF_color = sceDF.apply(lambda SS: SS.apply(lambda T: pairs2DFm[SS.name][T[0]]), axis=1)\n",
    "\n",
    "#te = None\n",
    "#if cDF is None:\n",
    "#    te = get_E_for_SS(DF[target_field])    \n",
    "#else:\n",
    "#    total_E = get_E_for_SS(DF[target_field])\n",
    "#    total_kl_divergence = get_E_for_SS(DF[target_field], cSS=cDF[target_field])\n",
    "#legend_value1 = total_E - total_kl_divergence\n",
    "#legend_value2 = total_E                                                 \n",
    "#scale = get_scale(total_E, RADIUS_FOR_TOTAL_MUTUAL_INFORMATION)\n",
    "#title, label = GRAPH_TITLE_2 % (target_field), GRAPH_DATASET_LABEL_2 % (target_field, total_E)        \n",
    "#mutualinfoSS = get_2v_MIs_for_DF_and_target_field(DF, target_field)\n",
    "#kldivergenceSS = get_2v_MIs_for_DF_and_target_field(DF, target_field, cDF=cDF)\n",
    "#background_singletons1_SS = mutualinfoSS - kldivergenceSS\n",
    "#background_singletons2_SS = mutualinfoSS\n",
    "#scmiDF = get_stepped_cMI_data_for_DF_and_target_field(DF,\n",
    "#            target_field, cDF=cDF)\n",
    "#imiDF, cmiDF = scmiDF.applymap(lambda T: T[1]), scmiDF.applymap(lambda T: T[2])\n",
    "#color_stepped_singletons_DF, size_stepped_singletons_DF = imiDF, cmiDF\n",
    "#field_by_field_pairs_DF = get_3v_MIs_for_DF_and_target_field(DF,\n",
    "#            target_field, cDF=cDF)\n",
    "#triplets_SS = -get_4v_MIs_for_DF_and_target_field(DF,\n",
    "#            target_field, cDF=cDF)\n",
    "\n",
    "#def get_E_for_SS2(SS, cSS=None, keySS=None, refEntropy=None, smooth_exp=1.0):\n",
    "#    p_counter = collect.Counter(SS)\n",
    "#    e = None\n",
    "#    if cSS is not None:\n",
    "#        q_counter = collect.Counter(cSS)\n",
    "#        pk, qk = [], []\n",
    "#        if keySS is None: keySS = pd.Series(sorted(list(set( p_counter.keys()) | set(q_counter.keys()) ))) \n",
    "#        for k in keySS:\n",
    "#            pk.append(((p_counter[k] if k in p_counter else 0) + 0.00001))\n",
    "#            qk.append(((q_counter[k] if k in q_counter else 0) + 0.00001)**smooth_exp)\n",
    "#        e = -stats.entropy(pk, qk=qk, base=2)    \n",
    "#    elif refEntropy is not None:\n",
    "#        e = stats.entropy(list(p_counter.values()), base=2) - refEntropy\n",
    "#    elif cSS is None and refEntropy is None:\n",
    "#        e = stats.entropy(list(p_counter.values()), base=2)\n",
    "#    return e\n",
    "\n",
    "#def get_jE_for_DF2(DF, cDF=None, smooth_exp=1.0):\n",
    "#    SS = superkey_DF(DF)\n",
    "#    cSS, keySS, refEntropy = None, None, None\n",
    "#    if type(cDF) == pd.DataFrame:\n",
    "#        kSSS1, kSSS2 = get_unique_values_for_DF(DF), get_unique_values_for_DF(cDF)\n",
    "#        kSSS = pd.Series([pd.Series(sorted(set(kSSS1[c]) | set(kSSS2[c]))) for c in DF.columns], index=DF.columns)\n",
    "#        keySS = cross_superkey_SS_of_SS(kSSS)\n",
    "#        cSS = superkey_DF(cDF)\n",
    "#    elif type(cDF) == pd.Series and not (False in [type(o) == pd.Series for o in cDF]):\n",
    "#        p = func.reduce(operate.mul, [len(SS) for SS in cDF])\n",
    "#        if p <= 100000:\n",
    "#            cSS = cross_superkey_SS_of_SS(cDF)\n",
    "#        else:\n",
    "#            refEntropy = math.log2(p)\n",
    "#    return get_E_for_SS2(SS, cSS=cSS, keySS=keySS, refEntropy=refEntropy, smooth_exp=smooth_exp)\n",
    "\n",
    "#def get_Es_for_DF2(DF, cDF=None, smooth_exp=1.0):\n",
    "#    cL, eL = DF.columns, None\n",
    "#    if cDF is None: eL = [get_E_for_SS2(DF[c]) for c in cL]\n",
    "#    else: eL = [get_E_for_SS2(DF[c], cSS=cDF[c], smooth_exp=smooth_exp) for c in cL]\n",
    "#    return pd.Series(eL, index=cL)\n",
    "\n",
    "#def get_2v_jEs_for_DF2(DF, cDF=None, smooth_exp=1.0):\n",
    "#    cDje = {}\n",
    "#    for i, c in enumerate(DF.columns):\n",
    "#        cDje[c] = []\n",
    "#        for j, c2 in enumerate(DF.columns):\n",
    "#            if cDF is None:\n",
    "#                cDje[c].append(get_jE_for_DF2(DF[[c, c2]]) if i > j else np.NaN)\n",
    "#            else:\n",
    "#                cDje[c].append(get_jE_for_DF2(DF[[c, c2]], cDF=cDF[[c, c2]], \n",
    "#                            smooth_exp=smooth_exp) if i > j else np.NaN)\n",
    "#    return pd.DataFrame(cDje, columns=DF.columns, index=DF.columns)\n",
    "\n",
    "#def get_2v_MIs_for_DF2(DF, cDF=None, smooth_exp=1.0):\n",
    "#    eSS = get_Es_for_DF2(DF, cDF=cDF, smooth_exp=smooth_exp)\n",
    "#    jeDF = get_2v_jEs_for_DF2(DF, cDF=cDF, smooth_exp=smooth_exp)    \n",
    "#    return pd.DataFrame({c: [eSS[c]+eSS[c2]-jeDF[c][c2] for c2 in DF.columns] for c in DF.columns}, index = DF.columns)\n",
    "\n",
    "#def get_3v_jEs_for_DF2(DF, cDF=None, smooth_exp=1.0):\n",
    "#    c1c2c3L, je3L = [], []\n",
    "#    for i in range(DF.shape[1]):\n",
    "#        for j in range(i+1, DF.shape[1]):\n",
    "#            for k in range(j+1, DF.shape[1]):\n",
    "#                c1, c2, c3, je3 = DF.columns[i], DF.columns[j], DF.columns[k], None\n",
    "#                if cDF is None:\n",
    "#                    je3 = get_jE_for_DF2( DF[[c1,c2,c3]] )\n",
    "#                else:\n",
    "#                    je3 = get_jE_for_DF2(DF[[c1,c2,c3]], cDF=cDF[[c1,c2,c3]], smooth_exp=smooth_exp)\n",
    "#                c1c2c3L.append((c1,c2,c3))\n",
    "#                je3L.append(je3)\n",
    "#    return pd.Series(je3L, index=c1c2c3L)\n",
    "\n",
    "#def get_3v_MIs_for_DF2(DF, cDF=None, smooth_exp=1.0):\n",
    "#    eSS = get_Es_for_DF2(DF, cDF=cDF, smooth_exp=smooth_exp)\n",
    "#    jeDF = get_2v_jEs_for_DF2(DF, cDF=cDF, smooth_exp=smooth_exp)\n",
    "#    tjeSS = get_3v_jEs_for_DF2(DF, cDF=cDF,smooth_exp=smooth_exp)    \n",
    "#    tmiL, cxcyczL = [], []\n",
    "#    for i in range(DF.shape[1]):\n",
    "#        for j in range(i+1, DF.shape[1]):\n",
    "#            for k in range(j+1, DF.shape[1]):\n",
    "#                cX, cY ,cZ = DF.columns[i], DF.columns[j], DF.columns[k]\n",
    "#                eX, eY, eZ = eSS[cX], eSS[cY], eSS[cZ]\n",
    "#                jeXY, jeXZ, jeYZ = jeDF[cY][cX], jeDF[cZ][cX], jeDF[cZ][cY]  \n",
    "#                tje = tjeSS[(cX,cY,cZ)]\n",
    "#                tmi = tje+eX+eY+eZ-jeXZ-jeXY-jeYZ\n",
    "#                tmiL.append(tmi)\n",
    "#                cxcyczL.append((cX,cY,cZ))\n",
    "#    return pd.Series(tmiL, index=cxcyczL)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
